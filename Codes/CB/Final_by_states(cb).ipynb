{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Final_by_states(cb).ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"TPU"},"cells":[{"cell_type":"code","metadata":{"id":"wJE3CqCPlekG","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1594260333345,"user_tz":-480,"elapsed":1275,"user":{"displayName":"余凯","photoUrl":"","userId":"13334016005065607071"}},"outputId":"70bd3086-9bfb-4b42-a153-816d325c51a0"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"DNIG9EtMl4ON","colab_type":"text"},"source":["## 导入工具包及设置路径"]},{"cell_type":"code","metadata":{"id":"qZ_FWMeSlk4N","colab_type":"code","colab":{}},"source":["import numpy as np\n","import pandas as pd\n","import os, sys, gc, time, warnings, pickle, psutil, random\n","from multiprocessing import Pool   \n","\n","warnings.filterwarnings('ignore')\n","fea_pkl_path = '/content/drive/My Drive/m5-forecasting-accuracy/SilverCode(final)/pkl/fea_pkl/'\n","model_pkl_path = '/content/drive/My Drive/m5-forecasting-accuracy/SilverCode(final)/pkl/model_pkl/'\n","datasets_path = '/content/drive/My Drive/m5-forecasting-accuracy/SilverCode(final)/datasets/'\n","fea_path = '/content/drive/My Drive/m5-forecasting-accuracy/SilverCode(final)/Features/'\n","pred_path = '/content/drive/My Drive/m5-forecasting-accuracy/SilverCode(final)/Predict/'\n","sub_path = '/content/drive/My Drive/m5-forecasting-accuracy/SilverCode(final)/Predict/sub/'\n","\n","BASE = fea_pkl_path + 'grid_part_1.pkl'\n","PRICE = fea_pkl_path + 'grid_part_2.pkl'\n","CALENDAR = fea_pkl_path + 'grid_part_3.pkl'\n","LAGS = fea_pkl_path + 'grid_part_4.pkl'\n","MEAN_ENC = fea_pkl_path + 'grid_part_5.pkl'"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"8anlfhfvl0v3","colab_type":"text"},"source":["## 基本函数"]},{"cell_type":"code","metadata":{"id":"M3v6yBvitYGM","colab_type":"code","colab":{}},"source":["## 设定随机种子\n","def seed_everything(seed=0):\n","  random.seed(seed)\n","  np.random.seed(seed)\n","\n","## 按照商店读取数据\n","def get_data_by_state(state):\n","  df = pd.concat([pd.read_pickle(BASE), # 9\n","            pd.read_pickle(PRICE).iloc[:,2:], # 11\n","            pd.read_pickle(CALENDAR).iloc[:,2:], # 15 \n","            pd.read_pickle(LAGS).iloc[:,3:], # 37\n","            pd.read_pickle(MEAN_ENC)[mean_features]], # 14(按商店只有6)  \n","            axis=1) \n","  # df：(47735397, 86)由于行数相同，可以横向拼接\n","  df = df[df['state_id'] == state] \n","  features = [col for col in list(df) if col not in remove_features] # 86 - 6(BASE) - 1(Holiday) = 79\n","  df = df[['id', 'd', TARGET] + features] # 79 + 3 = 82 相当于去掉了 'state_id', 'store_id', 'release', 'Holiday'(在CALENDAR里面)\n","  # 选训练开始的天数\n","  df = df[df['d'] >= START_TRAIN].reset_index(drop=True)\n","  return df, features\n","\n","\n","## 读取测试数据\n","def get_base_test():\n","  base_test = pd.DataFrame()\n","\n","  if USE_AUX:\n","    model_path = model_pkl_path\n","  else:\n","    model_path=''\n","    \n","  for state_id in STATE_IDS: \n","    temp_df = pd.read_pickle(model_path + 'cb_test_{}.pkl'.format(state_id)) # 不含lag + rolling特征\n","    temp_df['state_id'] = state_id\n","    base_test = pd.concat([base_test, temp_df]).reset_index(drop=True) # 纵向拼接\n","  \n","  return base_test\n","## 制作lag特征\n","def make_lag(LAG_DAY):\n","  lag_df = base_test[['id','d',TARGET]]\n","  col_name = 'sales_lag_' + str(LAG_DAY)\n","  lag_df[col_name] = lag_df.groupby(['id'])[TARGET].transform(lambda x: x.shift(LAG_DAY)).astype(np.float16)\n","  return lag_df[[col_name]]\n","## 递归特征\n","def make_lag_roll(LAG_DAY):\n","  shift_day = LAG_DAY[0]\n","  roll_wind = LAG_DAY[1]\n","  lag_df = base_test[['id','d',TARGET]]\n","  col_name = 'rolling_mean_tmp_'+str(shift_day)+'_'+str(roll_wind)\n","  lag_df[col_name] = lag_df.groupby(['id'])[TARGET].transform(lambda x: x.shift(shift_day).rolling(roll_wind).mean())\n","  return lag_df[[col_name]]\n","## 多线程执行，用于测试集融合\n","def df_parallelize_run(func, t_split):\n","  num_cores = np.min([N_CORES,len(t_split)])\n","  pool = Pool(num_cores)\n","  df = pd.concat(pool.map(func, t_split), axis=1)\n","  pool.close()\n","  pool.join()\n","  return df\n","\n","# lag + rolling\n","SHIFT_DAY = 28\n","N_LAGS = 15\n","LAGS_SPLIT = [col for col in range(SHIFT_DAY, SHIFT_DAY + N_LAGS)]\n","ROLS_SPLIT = []\n","for i in [1,7,14]:\n","  for j in [7,14,30,60]:\n","    ROLS_SPLIT.append([i,j])\n","   \n","USE_AUX = False\n","if USE_AUX:\n","  lgb_params['n_estimators'] = 2\n","\n","VER = 1 # 设置模型的版本\n","SEED = 42 \n","seed_everything(SEED) # 消除随机性\n","N_CORES = psutil.cpu_count() # 可使用的CPU内核\n","\n","TARGET = 'sales' # Label\n","START_TRAIN = 0 # 能跳过一些行(Nans/faster training)\n","P_HORIZON = 28 # 预测范围\n","USE_AUX = True # 使用预训练好的模型             \n","\n","remove_features = ['id', 'state_id', 'store_id', 'release', 'd', 'Holiday', TARGET]                    \n","mean_features   = [ 'enc_cat_id_mean', 'enc_cat_id_std', \n","             'enc_store_id_mean', 'enc_store_id_std', \n","             'enc_dept_id_mean', 'enc_dept_id_std', \n","             'enc_item_id_mean', 'enc_item_id_std', \n","             'enc_item_id_store_id_mean', 'enc_item_id_store_id_std',\n","             'enc_store_id_cat_id_std', 'enc_state_id_cat_id_std',\n","             'enc_store_id_dept_id_mean', 'enc_store_id_dept_id_std' ]  # 14\n","# 按州分别训练，每个州可以按商店、类别、部门、商品的销量聚合取mean\\std，可以选这14个特征"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Mk_wZzq9snqp","colab_type":"text"},"source":["## cb模型参数"]},{"cell_type":"code","metadata":{"id":"TLHbJ6BosmcK","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":361},"executionInfo":{"status":"ok","timestamp":1594260347228,"user_tz":-480,"elapsed":15123,"user":{"displayName":"余凯","photoUrl":"","userId":"13334016005065607071"}},"outputId":"aa1a9d17-d948-4240-d746-c81740599dc9"},"source":["!pip install catboost\n","from catboost import Pool, CatBoostRegressor \n","# Pool是catboost中的用于组织数据的一种形式，也可以用numpy、array和dataframe，但更推荐Pool，其内存和速度都更优。\n","cb_params_common = { \n","         'iterations' : 1524,\n","         'learning_rate' : 0.08868565834866991,\n","         'l2_leaf_reg' : 9.398124479877186,    \n","         'subsample' : 0.786596695482429,\n","         'max_depth' : 7,\n","         'boosting_type' : 'Plain',\n","         'one_hot_max_size' : 2,\n","         'max_bin' : 142,\n","         'objective' : 'RMSE',\n","         'eval_metric' : 'RMSE',\n","         'random_seed' : 42,\n","         'leaf_estimation_method' : 'Gradient',\n","         'nan_mode' : 'Max',\n","         'min_data_in_leaf' : 11965,\n","         'boost_from_average' : False,\n","         'verbose' : 100,\n","         'early_stopping_rounds' : 50 # 用earlystopping后训练时间更短，可以有效避免过拟合，得到的模型准确率更高。\n","        }"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Collecting catboost\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b2/aa/e61819d04ef2bbee778bf4b3a748db1f3ad23512377e43ecfdc3211437a0/catboost-0.23.2-cp36-none-manylinux1_x86_64.whl (64.8MB)\n","\u001b[K     |████████████████████████████████| 64.8MB 69kB/s \n","\u001b[?25hRequirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from catboost) (1.18.5)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from catboost) (3.2.2)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from catboost) (1.12.0)\n","Requirement already satisfied: plotly in /usr/local/lib/python3.6/dist-packages (from catboost) (4.4.1)\n","Requirement already satisfied: graphviz in /usr/local/lib/python3.6/dist-packages (from catboost) (0.10.1)\n","Requirement already satisfied: pandas>=0.24.0 in /usr/local/lib/python3.6/dist-packages (from catboost) (1.0.5)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from catboost) (1.4.1)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->catboost) (1.2.0)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->catboost) (2.4.7)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->catboost) (0.10.0)\n","Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->catboost) (2.8.1)\n","Requirement already satisfied: retrying>=1.3.3 in /usr/local/lib/python3.6/dist-packages (from plotly->catboost) (1.3.3)\n","Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.24.0->catboost) (2018.9)\n","Installing collected packages: catboost\n","Successfully installed catboost-0.23.2\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"vex2uvzs6TKm","colab_type":"text"},"source":["## 每个州单独训练(按州TX聚合效果差，只聚合CA和WI)"]},{"cell_type":"code","metadata":{"id":"VyhF8v21tjdy","colab_type":"code","colab":{}},"source":["STATE_IDS = ['CA','WI'] \n","END_TRAIN = 1941"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"NI1vHx6nOEhE","colab_type":"code","colab":{}},"source":["# features_columns = ['item_id', 'dept_id', 'cat_id', 'sell_price', 'price_max', 'price_min', 'price_std', 'price_mean', 'price_norm', 'price_nunique', 'item_nunique', 'price_momentum', 'price_momentum_m', 'price_momentum_y', 'event_name_1', 'event_type_1', 'event_name_2', 'event_type_2', 'snap_CA', 'snap_TX', 'snap_WI', 'tm_d', 'tm_w', 'tm_m', 'tm_y', 'tm_wm', 'tm_dw', 'tm_w_end', 'sales_lag_28', 'sales_lag_29', 'sales_lag_30', 'sales_lag_31', 'sales_lag_32', 'sales_lag_33', 'sales_lag_34', 'sales_lag_35', 'sales_lag_36', 'sales_lag_37', 'sales_lag_38', 'sales_lag_39', 'sales_lag_40', 'sales_lag_41', 'sales_lag_42', 'rolling_mean_7', 'rolling_std_7', 'rolling_mean_14', 'rolling_std_14', 'rolling_mean_30', 'rolling_std_30', 'rolling_mean_60', 'rolling_std_60', 'rolling_mean_180', 'rolling_std_180', 'rolling_mean_tmp_1_7', 'rolling_mean_tmp_1_14', 'rolling_mean_tmp_1_30', 'rolling_mean_tmp_1_60', 'rolling_mean_tmp_7_7', 'rolling_mean_tmp_7_14', 'rolling_mean_tmp_7_30', 'rolling_mean_tmp_7_60', 'rolling_mean_tmp_14_7', 'rolling_mean_tmp_14_14', 'rolling_mean_tmp_14_30', 'rolling_mean_tmp_14_60', 'enc_cat_id_mean', 'enc_cat_id_std', 'enc_store_id_mean', 'enc_store_id_std', 'enc_dept_id_mean', 'enc_dept_id_std', 'enc_item_id_mean', 'enc_item_id_std', 'enc_item_id_store_id_mean', 'enc_item_id_store_id_std', 'enc_store_id_cat_id_std', 'enc_state_id_cat_id_std', 'enc_store_id_dept_id_mean', 'enc_store_id_dept_id_std']\n","# 79"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"WY8SZerBtlJ7","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":107},"outputId":"e05d3cef-5265-4b3e-88a6-9ce0bee9afb6"},"source":["for state_id in STATE_IDS:\n","  print('Train', state_id)\n","  grid_df, features_columns = get_data_by_state(state_id) \n","  ########################## 添加节假日特性 #############################\n","  calendar_win = pd.read_csv(datasets_path + 'calendar.csv')[['event_name_2','event_name_1','d']]\n","  # 添加特征\n","  event = calendar_win[['event_name_2','event_name_1']].fillna('') \n","  # 整体上移一天\n","  event_before1 = pd.DataFrame()\n","  event_up_one = event.shift(-1).fillna('') \n","  event_before1['event_name_2'] = event_up_one['event_name_2'].apply(lambda x: x + '_before1' if x != '' else x)\n","  event_before1['event_name_1'] = event_up_one['event_name_1'].apply(lambda x: x + '_before1' if x != '' else x)\n","  # 整体上移两天\n","  event_before2 = pd.DataFrame()\n","  event_up_two = event.shift(-2).fillna('')   \n","  event_before2['event_name_2'] = event_up_two['event_name_2'].apply(lambda x: x + '_before2' if x != '' else x)\n","  event_before2['event_name_1'] = event_up_two['event_name_1'].apply(lambda x: x + '_before2' if x != '' else x)\n","  event_win = event_before1 + event_before2\n","\n","  calendar_win.drop(columns=['event_name_1','event_name_2'],inplace=True)\n","\n","  # 转换数据类型\n","  calendar_win['event_name_1_win'] = event_win['event_name_1'].astype('category')\n","  calendar_win['event_name_2_win'] = event_win['event_name_2'].astype('category')\n","  calendar_win['d'] = calendar_win['d'].apply(lambda x: x.split('_',2)[1]).astype(np.int16)\n","\n","  # 小融入大 merge\n","  grid_df = grid_df.merge(calendar_win, on='d', how='left')\n","  features_columns = features_columns + ['event_name_1_win','event_name_2_win']\n","\n","  if state_id == 'CA':\n","    cb_params = cb_params_common\n","  elif state_id == 'WI':\n","    cb_params = cb_params_common\n","\n","  train_mask = grid_df['d'] <= END_TRAIN - P_HORIZON # 1<= train <=1941-28 \n","  valid_mask = (grid_df['d'] > END_TRAIN - P_HORIZON) & (grid_df['d'] <= END_TRAIN) # 1941-28< valid <=1941\n","  preds_mask = grid_df['d'] > END_TRAIN - 100 # 1941-100< test <=1969 \n","\n","  categorical_features_indices = ['item_id','dept_id','cat_id','snap_CA','snap_TX','snap_WI',\n","                    'event_name_1','event_type_1','event_name_2','event_type_2',\n","                    'event_name_1_win','event_name_2_win']\n","  for i in categorical_features_indices:\n","    grid_df[i] = grid_df[i].astype('object') # 类别数据的类型要是object\n","    grid_df[i] = grid_df[i].fillna('no') # 注意：cb中不能出现空值，类别列也不可以\n","\n","  train_pool = Pool(grid_df[train_mask][features_columns], grid_df[train_mask][TARGET], cat_features = categorical_features_indices) \n","  valid_pool = Pool(grid_df[valid_mask][features_columns], grid_df[valid_mask][TARGET], cat_features = categorical_features_indices)\n","\n","  grid_df = grid_df[preds_mask].reset_index(drop=True) \n","  keep_cols = [col for col in list(grid_df) if '_tmp_' not in col]\n","  # 细节：在测试集中去掉了递归特征\n","  grid_df = grid_df[keep_cols] \n","  grid_df.to_pickle(model_pkl_path + 'cb_test_{}.pkl'.format(state_id))\n","  \n","  # 训练模型\n","  seed_everything(SEED)\n","  cb_model = CatBoostRegressor(**cb_params) \n","  cb_model.fit(train_pool, eval_set = valid_pool) \n","  # 存储模型为二进制文件，下次读取的时候，速度更快\n","  model_name = model_pkl_path + 'cb_model_{}_v{}.bin'.format(state_id, str(VER))\n","  pickle.dump(cb_model, open(model_name, 'wb'))\n","\n","  del grid_df, train_pool, valid_pool, cb_model\n","\n","  MODEL_FEATURES = features_columns"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Train CA\n","0:\tlearn: 4.5785288\ttest: 3.6324570\tbest: 3.6324570 (0)\ttotal: 5.25s\tremaining: 2h 13m 18s\n","100:\tlearn: 2.4862629\ttest: 1.9786582\tbest: 1.9786582 (100)\ttotal: 6m 12s\tremaining: 1h 27m 34s\n","200:\tlearn: 2.4363563\ttest: 1.9637915\tbest: 1.9637915 (200)\ttotal: 12m 25s\tremaining: 1h 21m 49s\n","300:\tlearn: 2.4115216\ttest: 1.9573065\tbest: 1.9572969 (299)\ttotal: 18m 42s\tremaining: 1h 16m 2s\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"u-FwIImBiVD4","colab_type":"text"},"source":["## 预测"]},{"cell_type":"code","metadata":{"id":"4ocYPQzUiIi9","colab_type":"code","colab":{}},"source":["# 训练特征 79 + 2 = 81 \n","# MODEL_FEATURES = ['item_id', 'dept_id', 'cat_id', 'sell_price', 'price_max', 'price_min', 'price_std', 'price_mean', 'price_norm', 'price_nunique', 'item_nunique', 'price_momentum', 'price_momentum_m', 'price_momentum_y', 'event_name_1', 'event_type_1', 'event_name_2', 'event_type_2', 'snap_CA', 'snap_TX', 'snap_WI', 'tm_d', 'tm_w', 'tm_m', 'tm_y', 'tm_wm', 'tm_dw', 'tm_w_end', 'sales_lag_28', 'sales_lag_29', 'sales_lag_30', 'sales_lag_31', 'sales_lag_32', 'sales_lag_33', 'sales_lag_34', 'sales_lag_35', 'sales_lag_36', 'sales_lag_37', 'sales_lag_38', 'sales_lag_39', 'sales_lag_40', 'sales_lag_41', 'sales_lag_42', 'rolling_mean_7', 'rolling_std_7', 'rolling_mean_14', 'rolling_std_14', 'rolling_mean_30', 'rolling_std_30', 'rolling_mean_60', 'rolling_std_60', 'rolling_mean_180', 'rolling_std_180', 'rolling_mean_tmp_1_7', 'rolling_mean_tmp_1_14', 'rolling_mean_tmp_1_30', 'rolling_mean_tmp_1_60', 'rolling_mean_tmp_7_7', 'rolling_mean_tmp_7_14', 'rolling_mean_tmp_7_30', 'rolling_mean_tmp_7_60', 'rolling_mean_tmp_14_7', 'rolling_mean_tmp_14_14', 'rolling_mean_tmp_14_30', 'rolling_mean_tmp_14_60', 'enc_cat_id_mean', 'enc_cat_id_std', 'enc_store_id_mean', 'enc_store_id_std', 'enc_dept_id_mean', 'enc_dept_id_std', 'enc_item_id_mean', 'enc_item_id_std', 'enc_item_id_store_id_mean', 'enc_item_id_store_id_std', 'enc_store_id_cat_id_std', 'enc_state_id_cat_id_std', 'enc_store_id_dept_id_mean', 'enc_store_id_dept_id_std', 'event_name_1_win', 'event_name_2_win']"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"iGQPtpnQtsBq","colab_type":"code","colab":{}},"source":["USE_AUX = True\n","END_TRAIN = 1941\n","all_preds = pd.DataFrame()\n","base_test = get_base_test() # [2731904 rows x 73 columns]\n","main_time = time.time()\n","       \n","for PREDICT_DAY in range(1,29):    \n","    print('Predict | Day:', PREDICT_DAY)\n","    start_time = time.time()\n","\n","    # 加上测试集\"lag+rolling\"特征(12个)\n","    grid_df = base_test.copy() \n","    grid_df = pd.concat([grid_df, df_parallelize_run(make_lag_roll, ROLS_SPLIT)], axis=1)\n","\n","    for state_id in STATE_IDS:\n","      model_bin = 'cb_model_{}_v{}.bin'.format(state_id, str(VER))\n","      if USE_AUX:\n","        model_path = model_pkl_path + model_bin\n","      # 加载训练好的模型\n","      cb_model = pickle.load(open(model_path, 'rb'))\n","      \n","      day_mask = base_test['d'] == END_TRAIN + PREDICT_DAY \n","      store_mask = base_test['state_id'] == state_id \n","      mask = (day_mask) & (store_mask) \n","\n","      categorical_features_indices = ['item_id','dept_id','cat_id','snap_CA','snap_TX','snap_WI',\n","                        'event_name_1','event_type_1','event_name_2','event_type_2',\n","                        'event_name_1_win','event_name_2_win']\n","      for i in categorical_features_indices:\n","        grid_df[i] = grid_df[i].astype('object')\n","        grid_df[i] = grid_df[i].fillna('no') \n","\n","      base_test[TARGET][mask] = cb_model.predict(grid_df[mask][MODEL_FEATURES])\n","      # 比如预测得到的1942这一天的销量，把它填充到base_test的\"sales\"对应1942这一天\"NAN\"值\n","      # 所以，base_test的\"sales\"一直在变，所以下面预测1943这一天的销量，会用到前面1942这一天的预测值\n","\n","    temp_df = base_test[day_mask][['id',TARGET]]\n","    temp_df.columns = ['id', 'F{}'.format(str(PREDICT_DAY))]\n","    if 'id' in list(all_preds):\n","      all_preds = all_preds.merge(temp_df, on=['id'], how='left')\n","    else:\n","      all_preds = temp_df.copy()\n","        \n","    print('#'*10, ' %0.2f min round |' % ((time.time() - start_time) / 60),\n","            ' %0.2f min total |' % ((time.time() - main_time) / 60),\n","            ' %0.2f day sales |' % (temp_df['F'+str(PREDICT_DAY)].sum()))\n","    del temp_df\n","    \n","all_preds = all_preds.reset_index(drop=True)\n","all_preds.to_csv(pred_path + 'per_state(WI+CA)_pred(cb).csv')\n","\n","# 用于生成提交预测的文件\n","submission = pd.read_csv(datasets_path + 'sample_submission.csv')[['id']] # [[]] 返回DataFrame [] 返回Series\n","submission = submission.merge(all_preds, on=['id'], how='left').fillna(0)\n","submission.to_csv(datasets_path + 'submission_by_states(cb).csv'), index=False) "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"jDeLvQS7IBBF","colab_type":"text"},"source":["## 某个州进行贝叶斯调参"]},{"cell_type":"code","metadata":{"id":"GgQkBLiQIAgd","colab_type":"code","colab":{}},"source":["STATE_IDS = 'TX'\n","grid_df, features_columns = get_data_by_state(STATE_IDS)\n","day = 1941\n","grid_df1 = grid_df[grid_df['d'] <= day] \n","del grid_df\n","\n","!pip install bayesian-optimization\n","\n","import lightgbm as lgb\n","from bayes_opt import BayesianOptimization\n","# 定义RMSE\n","def rmse(y, y_pred):\n","  return np.sqrt(np.mean(np.square(y - y_pred)))\n","\n","df = grid_df1\n","fe = features_columns\n","# 1000到1941-28-28 作为训练集\n","tr_x, tr_y = df[(df['d'] >= 1000) & (df['d'] <= (day-28-28))][fe], df[(df['d'] >= 1000) & (df['d'] <= (day-28-28))]['sales'] \n","# 1941-28-28到1941-28 作为验证集\n","vl_x, vl_y = df[(df['d'] > (day-28-28)) & (df['d'] <= (day-28))][fe], df[(df['d'] > (day-28-28)) & (df['d'] <= (day-28))]['sales']\n","\n","train_data = lgb.Dataset(tr_x, label = tr_y)\n","valid_data = lgb.Dataset(vl_x, label = vl_y)\n","\n","# 1914到1941 作为测试集，用训练的模型预测它的\"sales\"，再与真实的\"sales\"计算RMSE\n","test_df = df[df['d'] > day-28].reset_index(drop=True) \n","\n","# 定义黑盒函数\n","def lgb_cv(tweedie_variance_power, subsample, subsample_freq, learning_rate, num_leaves, min_data_in_leaf,\n","      feature_fraction, max_bin, n_estimators, lambda_l2, sub_row, sub_feature, bagging_freq):\n","\n","\n","    lgb_params = {\n","                    'boosting_type': 'gbdt',\n","                    'objective': 'tweedie',\n","                    'tweedie_variance_power': tweedie_variance_power,\n","                    'metric': 'rmse',\n","                    'subsample': subsample,\n","                    'subsample_freq': int(subsample_freq),\n","                    'learning_rate': learning_rate,\n","                    'num_leaves': int(num_leaves),\n","                    'min_data_in_leaf': int(min_data_in_leaf),\n","                    'feature_fraction': feature_fraction,\n","                    'max_bin': int(max_bin),\n","                    'n_estimators': int(n_estimators),\n","                    'boost_from_average': False,\n","                    'seed': 42,  \n","                    'lambda_l2':lambda_l2,\n","                    'sub_row':sub_row,  \n","                    'sub_feature':sub_feature,\n","                    'bagging_freq':int(bagging_freq)          \n","                }\n","    stimator = lgb.train(lgb_params, train_data, num_boost_round = 10000, valid_sets = [valid_data], verbose_eval = 100, early_stopping_rounds = 100) \n","    # valid_sets = [train_data, valid_data] 这个是用来显示training's rmse和valid_1's rmse，这里不用显示，就不要了\n","    # verbose_eval : 迭代多少次打印\n","    test_df['preds'] = stimator.predict(test_df[fe], num_iteration = stimator.best_iteration)\n","    base_score = rmse(test_df['sales'], test_df['preds'])\n","\n","    return -base_score\n","\n","# 给定超参数搜索空间\n","opt = BayesianOptimization(\n","                lgb_cv,\n","                {\n","                    'tweedie_variance_power': (1, 1.3),\n","                    'subsample': (0.5, 1.0),\n","                    'subsample_freq': (0, 5),\n","                    'learning_rate': (0, 1),\n","                    'num_leaves':(2**10-1,2**15-1),\n","                    'min_data_in_leaf':(2**10-1,2**15-1),\n","                    'feature_fraction':(0.4,1),\n","                    'max_bin':(80,150),\n","                    'n_estimators':(1000,1700),\n","                    'lambda_l2':(0,0.2),\n","                    'sub_row':(0.6,1),\n","                    'sub_feature':(0.6,1.0),\n","                    'bagging_freq':(0,5),\n","                }\n","              )\n","opt.maximize(n_iter = 20) # 最大化黑盒函数\n","rf_bo.max # 返回黑盒函数值最大的超参数"],"execution_count":null,"outputs":[]}]}