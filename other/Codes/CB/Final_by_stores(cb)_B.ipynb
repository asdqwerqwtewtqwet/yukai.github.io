{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Final_by_stores(cb).ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"TPU"},"cells":[{"cell_type":"code","metadata":{"id":"z_5SVT6RvYYq","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":127},"executionInfo":{"status":"ok","timestamp":1594251494526,"user_tz":-480,"elapsed":21607,"user":{"displayName":"余凯","photoUrl":"","userId":"13334016005065607071"}},"outputId":"bc5b48be-bcef-41ea-ef21-79b53c578d22"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"jiFkJMb3Ey0F","colab_type":"code","colab":{}},"source":["import numpy as np\n","import pandas as pd\n","import os, sys, gc, time, warnings, pickle, psutil, random\n","import lightgbm as lgb\n","import multiprocessing as mul \n","# BUG点：from multiprocessing import Pool 这里只能用 mul.Pool，不然系统会误以为调用caboost里面的Pool       \n","warnings.filterwarnings('ignore')\n","\n","fea_pkl_path = '/content/drive/My Drive/m5-forecasting-accuracy/SilverCode(final)/pkl/fea_pkl/'\n","model_pkl_path = '/content/drive/My Drive/m5-forecasting-accuracy/SilverCode(final)/pkl/model_pkl/'\n","datasets_path = '/content/drive/My Drive/m5-forecasting-accuracy/SilverCode(final)/datasets/'\n","fea_path = '/content/drive/My Drive/m5-forecasting-accuracy/SilverCode(final)/Features/'\n","pred_path = '/content/drive/My Drive/m5-forecasting-accuracy/SilverCode(final)/Predict/'\n","sub_path = '/content/drive/My Drive/m5-forecasting-accuracy/SilverCode(final)/Predict/sub/'\n","\n","BASE = fea_pkl_path + 'grid_part_1.pkl'\n","PRICE = fea_pkl_path + 'grid_part_2.pkl'\n","CALENDAR = fea_pkl_path + 'grid_part_3.pkl'\n","LAGS = fea_pkl_path + 'grid_part_4.pkl'\n","MEAN_ENC = fea_pkl_path + 'grid_part_5.pkl'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"RhPOT38tOl_q","colab_type":"code","colab":{}},"source":["## 设定随机种子\n","def seed_everything(seed=0):\n","  random.seed(seed)\n","  np.random.seed(seed)\n","\n","## 按照商店读取数据\n","def get_data_by_store(store):\n","    # 读取和连接基本特征\n","    df = pd.concat([pd.read_pickle(BASE), # 9\n","             pd.read_pickle(PRICE).iloc[:,2:], # 11\n","             pd.read_pickle(CALENDAR).iloc[:,2:], # 15 \n","             pd.read_pickle(LAGS).iloc[:,3:], # 37\n","             pd.read_pickle(MEAN_ENC)[mean_features]], # 6  \n","             axis=1) \n","    # df：(47735397, 78)由于行数相同，可以横向拼接\n","    df = df[df['store_id'] == store] # df['store_id'] == store 返回布尔Series，df[df['store_id'] == store] 然后取True的行构成的dataframe\n","    features = [col for col in list(df) if col not in remove_features] # 78 - 7 = 71\n","    df = df[['id', 'd', TARGET] + features] # 71 + 3 = 74 相当于去掉了 'state_id', 'store_id', 'release', 'Holiday'(在CALENDAR里面)\n","    # 选训练开始的天数\n","    df = df[df['d'] >= START_TRAIN].reset_index(drop=True) # drop = True去掉生成的原索引列\n","    return df, features\n","\n","\n","## 读取测试数据\n","def get_base_test():\n","  base_test = pd.DataFrame()\n","  \n","  if USE_AUX:\n","    model_path = model_pkl_path\n","  else:\n","    model_path=''\n","\n","  for store_id in STORES_IDS: \n","    temp_df = pd.read_pickle(model_path + 'cb_test_{}.pkl'.format(store_id)) # 不含lag + rolling特征\n","    temp_df['store_id'] = store_id\n","    base_test = pd.concat([base_test, temp_df]).reset_index(drop=True) # 纵向拼接\n","  \n","  return base_test\n","## 制作lag特征\n","def make_lag(LAG_DAY):\n","  lag_df = base_test[['id','d',TARGET]]\n","  col_name = 'sales_lag_' + str(LAG_DAY)\n","  lag_df[col_name] = lag_df.groupby(['id'])[TARGET].transform(lambda x: x.shift(LAG_DAY)).astype(np.float16)\n","  return lag_df[[col_name]]\n","## 递归特征\n","def make_lag_roll(LAG_DAY):\n","  shift_day = LAG_DAY[0]\n","  roll_wind = LAG_DAY[1]\n","  lag_df = base_test[['id','d',TARGET]]\n","  col_name = 'rolling_mean_tmp_'+str(shift_day)+'_'+str(roll_wind)\n","  lag_df[col_name] = lag_df.groupby(['id'])[TARGET].transform(lambda x: x.shift(shift_day).rolling(roll_wind).mean())\n","  return lag_df[[col_name]]\n","## 多线程执行，用于测试集融合\n","def df_parallelize_run(func, t_split):\n","  num_cores = np.min([N_CORES,len(t_split)])\n","  pool = mul.Pool(num_cores)\n","  df = pd.concat(pool.map(func, t_split), axis=1)\n","  pool.close()\n","  pool.join()\n","  return df\n","\n","# lag + rolling\n","SHIFT_DAY = 28\n","N_LAGS = 15\n","LAGS_SPLIT = [col for col in range(SHIFT_DAY, SHIFT_DAY + N_LAGS)]\n","ROLS_SPLIT = []\n","for i in [1,7,14]:\n","  for j in [7,14,30,60]:\n","    ROLS_SPLIT.append([i,j])\n","\n","VER = 1 # 设置模型的版本\n","SEED = 42 \n","seed_everything(SEED) # 消除随机性\n","N_CORES = psutil.cpu_count() # 可使用的CPU内核\n","\n","TARGET = 'sales' # Label\n","START_TRAIN = 0 # 能跳过一些行(Nans/faster training)\n","P_HORIZON = 28 # 预测范围\n","USE_AUX = True # 使用预训练好的模型\n","\n","remove_features = ['id', 'state_id', 'store_id', 'release', 'Holiday', 'd', TARGET]          \n","mean_features = ['enc_cat_id_mean', 'enc_cat_id_std', 'enc_dept_id_mean', 'enc_dept_id_std', 'enc_item_id_mean', 'enc_item_id_std'] \n","# 按商店分别训练，每个商店可以只能按类别、部门、商品的销量聚合取mean\\std，故只选这6个特征"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"N_R3Odek2Vl1","colab_type":"text"},"source":["## 每个商店的cb参数"]},{"cell_type":"code","metadata":{"id":"TbHapyQzzrcE","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":361},"executionInfo":{"status":"ok","timestamp":1594251517997,"user_tz":-480,"elapsed":11846,"user":{"displayName":"余凯","photoUrl":"","userId":"13334016005065607071"}},"outputId":"d42a0a7e-40e5-4366-e2b1-8badd854e02b"},"source":["!pip install catboost\n","from catboost import Pool, CatBoostRegressor \n","# Pool是catboost中的用于组织数据的一种形式，也可以用numpy、array和dataframe，但更推荐Pool，其内存和速度都更优。\n","cb_params_common = { \n","            'iterations' : 1524,\n","            'learning_rate' : 0.08868565834866991,\n","            'l2_leaf_reg' : 9.398124479877186,    \n","            'subsample' : 0.786596695482429,\n","            'max_depth' : 7,\n","            'boosting_type' : 'Plain',\n","            'one_hot_max_size' : 2,\n","            'max_bin' : 142,\n","            'objective' : 'RMSE',\n","            'eval_metric' : 'RMSE',\n","            'random_seed' : 42,\n","            'leaf_estimation_method' : 'Gradient',\n","            'nan_mode' : 'Max',\n","            'min_data_in_leaf' : 11965,\n","            'boost_from_average' : False,\n","            'verbose' : 100,\n","            'early_stopping_rounds' : 50 # 用earlystopping后训练时间更短，可以有效避免过拟合，得到的模型准确率更高。\n","           }"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Collecting catboost\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b2/aa/e61819d04ef2bbee778bf4b3a748db1f3ad23512377e43ecfdc3211437a0/catboost-0.23.2-cp36-none-manylinux1_x86_64.whl (64.8MB)\n","\u001b[K     |████████████████████████████████| 64.8MB 66kB/s \n","\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from catboost) (1.4.1)\n","Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from catboost) (1.18.5)\n","Requirement already satisfied: pandas>=0.24.0 in /usr/local/lib/python3.6/dist-packages (from catboost) (1.0.5)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from catboost) (3.2.2)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from catboost) (1.12.0)\n","Requirement already satisfied: graphviz in /usr/local/lib/python3.6/dist-packages (from catboost) (0.10.1)\n","Requirement already satisfied: plotly in /usr/local/lib/python3.6/dist-packages (from catboost) (4.4.1)\n","Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.24.0->catboost) (2.8.1)\n","Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.24.0->catboost) (2018.9)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->catboost) (1.2.0)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->catboost) (0.10.0)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->catboost) (2.4.7)\n","Requirement already satisfied: retrying>=1.3.3 in /usr/local/lib/python3.6/dist-packages (from plotly->catboost) (1.3.3)\n","Installing collected packages: catboost\n","Successfully installed catboost-0.23.2\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"52JVXYxX2heR","colab_type":"text"},"source":["## 每个商店单独训练模型"]},{"cell_type":"code","metadata":{"id":"C84oJ59GPJ25","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1594254801113,"user_tz":-480,"elapsed":3249769,"user":{"displayName":"余凯","photoUrl":"","userId":"13334016005065607071"}},"outputId":"e1e4a447-4445-4b54-c48b-161cec185ca7"},"source":["# STORES_IDS = ['CA_1','CA_2','CA_3','CA_4','TX_1','TX_2','TX_3','WI_1','WI_2','WI_3']\n","STORES_IDS = ['WI_1','WI_2','WI_3']\n","END_TRAIN = 1941\n","############################################# Train Models ###############################################\n","for store_id in STORES_IDS: # 每个商店单独训练\n","    print('Train', store_id)\n","    grid_df, features_columns = get_data_by_store(store_id) # grid_df：74 features_columns：71\n","\n","    ########################## 添加节假日特性 #############################\n","    ## CA1、TX2、TX3的特征的节假日效应类似，用同一个文件\n","    if (store_id=='CA_1') or (store_id=='TX_2') or (store_id=='TX_3'):\n","      calendar_win = pd.read_csv(fea_path + 'CA1_TX2_TX3_holidays.csv')\n","      calendar_win['d'] = calendar_win['d'].apply(lambda x: x.split('_',2)[1]).astype(np.int16) \n","      calendar_win['event_name_1_win'] = calendar_win['event_name_1_win'] \n","      grid_df = grid_df.merge(calendar_win, on='d', how='left') # 小维度融入大维度按共有列进行merge\n","\n","      features_columns = features_columns + ['event_name_1_win'] # 72\n","      if store_id=='CA1':\n","        cb_params = cb_params_common\n","      else:\n","        cb_params = cb_params_common\n","    ## CA2单独有自己的节假日效应\n","    elif store_id=='CA_2':\n","      calendar_win = pd.read_csv(fea_path + 'CA2_holidays.csv')\n","      calendar_win['d'] = calendar_win['d'].apply(lambda x: x.split('_',2)[1]).astype(np.int16)\n","      calendar_win['event_name_1_win'] = calendar_win['event_name_1_win']\n","      grid_df = grid_df.merge(calendar_win, on='d', how='left')\n","\n","      features_columns = features_columns+['event_name_1_win']\n","      cb_params = cb_params_common\n","    ## TX1的节假日效应，假设所有节假日的前一天和后一天都有一定的影响\n","    elif store_id=='TX_1':\n","      calendar_df = pd.read_csv(datasets_path + 'calendar.csv')\n","      calendar_win = calendar_df[['event_name_2','event_name_1','d']]\n","      calendar_win['d'] = calendar_win['d'].apply(lambda x: x.split('_',2)[1]).astype(np.int16)\n","\n","      # 添加特征\n","      event = calendar_df[['event_name_2','event_name_1']].fillna('') # 用''替换NAN(因为NAN为float类型)\n","      event_up_one = event.shift(-1).fillna('') # 上移之后，最后一行会出现NAN，需要再fillna('')一次\n","      event_before = pd.DataFrame()\n","      event_before['event_name_2'] = event_up_one['event_name_2'].apply(lambda x: x + '_before' if x != '' else x)\n","      event_before['event_name_1'] = event_up_one['event_name_1'].apply(lambda x: x + '_before' if x != '' else x)\n","      # 总结：对Series应用匿名函数时候，这一列必须是相同的数据类型，我要实现把节假日(字符串)改名字，这一列都必须要是str，所以把 NAN 填充为空字符串！\n","      # 这样，我就可以用匿名函数，返回的x是相同的数据类型。以后对含有空值的列处理其中的字符串元素的话，就要这么做，先填充，再apply匿名函数\n","      \n","      event_down_one = event.shift(1).fillna('') # 下移之后，第一行会出现NAN，需要再fillna('')一次\n","      event_after = pd.DataFrame()\n","      event_after['event_name_2'] = event_down_one['event_name_2'].apply(lambda x: x + '_after' if x != '' else x)\n","      event_after['event_name_1'] = event_down_one['event_name_1'].apply(lambda x: x + '_after' if x != '' else x)\n","\n","      even_win = event_before + event_after # 注意只有都是字符串列也可以对dataframe相加。另外，'' + '' = ''\n","\n","      even_win['event_name_2'] = even_win['event_name_2'].apply(lambda x: np.nan if x=='' else x)\n","      even_win['event_name_1'] = even_win['event_name_1'].apply(lambda x: np.nan if x=='' else x)\n","\n","      # 去掉原来的节假日列，增加新的两列\n","      calendar_win.drop(columns=['event_name_1','event_name_2'],inplace=True) \n","      calendar_win['event_name_1_win'] = even_win['event_name_1'] \n","      calendar_win['event_name_2_win'] = even_win['event_name_2']\n","      calendar_win['d'] = calendar_win['d'].astype(np.int16) \n","\n","      # 融入grid_df中，74 + 2 = 76\n","      grid_df = grid_df.merge(calendar_win, on='d', how='left') # calendar_win：'d'、'event_name_1_win'、'event_name_2_win'这三列\n","      features_columns = features_columns + ['event_name_1_win','event_name_2_win'] # 71 + 2 = 73\n","\n","      # 补充的节假日效应列\n","      calendar_win_1 = pd.read_csv(fea_path + 'CA1_TX2_TX3_holidays.csv')\n","      calendar_win_1.rename(columns = {'event_name_1_win':'event_name_1_win_1'},inplace=True)\n","      calendar_win_1['d'] = calendar_win_1['d'].apply(lambda x: x.split('_',2)[1]).astype(np.int16)\n","      grid_df = grid_df.merge(calendar_win_1, on='d', how='left')\n","      features_columns = features_columns + ['event_name_1_win_1']\n","\n","      # 设置模型参数\n","      cb_params = cb_params_common\n","\n","    ## WI1的节假日效应，假设所有节假日的前两天和后一天都有一定的影响\n","    elif store_id=='WI_1':\n","      calendar_df = pd.read_csv(datasets_path + 'calendar.csv')\n","      calendar_win = calendar_df[['event_name_2','event_name_1','d']]\n","      calendar_win['d'] = calendar_win['d'].apply(lambda x: x.split('_',2)[1]).astype(np.int16)\n","\n","      # 添加特征\n","      event = calendar_df[['event_name_2','event_name_1']].fillna('') \n","      # 上移\n","      event_before1 = pd.DataFrame()\n","      event_up_one = event.shift(-1).fillna('') \n","      event_before1['event_name_2'] = event_up_one['event_name_2'].apply(lambda x: x + '_before1' if x != '' else x)\n","      event_before1['event_name_1'] = event_up_one['event_name_1'].apply(lambda x: x + '_before1' if x != '' else x)\n","      event_before2 = pd.DataFrame()\n","      event_up_two = event.shift(-2).fillna('')   \n","      event_before2['event_name_2'] = event_up_two['event_name_2'].apply(lambda x: x + '_before2' if x != '' else x)\n","      event_before2['event_name_1'] = event_up_two['event_name_1'].apply(lambda x: x + '_before2' if x != '' else x)\n","      event_before = event_before1 + event_before2\n","      # 下移\n","      event_after = pd.DataFrame()\n","      event_down_one = event.shift(1).fillna('') \n","      event_after['event_name_2'] = event_down_one['event_name_2'].apply(lambda x: x + '_after' if x != '' else x)\n","      event_after['event_name_1'] = event_down_one['event_name_1'].apply(lambda x: x + '_after' if x != '' else x)\n","\n","      even_win = event_before + event_after \n","\n","      # 还原NAN\n","      even_win['event_name_2'] = even_win['event_name_2'].apply(lambda x: np.nan if x=='' else x)\n","      even_win['event_name_1'] = even_win['event_name_1'].apply(lambda x: np.nan if x=='' else x)\n","      # 去掉原来的节假日列，增加新的两列\n","      calendar_win.drop(columns=['event_name_1','event_name_2'],inplace=True) \n","      calendar_win['event_name_1_win'] = even_win['event_name_1']\n","      calendar_win['event_name_2_win'] = even_win['event_name_2']\n","      calendar_win['d'] = calendar_win['d'].astype(np.int16) \n","\n","      # 融入grid_df中，74 + 2 = 76\n","      grid_df = grid_df.merge(calendar_win, on='d', how='left') # calendar_win：'d'、'event_name_1_win'、'event_name_2_win'这三列\n","      features_columns = features_columns + ['event_name_1_win','event_name_2_win'] # 71 + 2 = 73\n","\n","      cb_params = cb_params_common\n","\n","    ## 独自的节假日效应\n","    elif store_id=='WI_3':\n","      calendar_win = pd.read_csv(fea_path + 'WI_3_holidays.csv')\n","      calendar_win['d'] = calendar_win['d'].apply(lambda x: x.split('_',2)[1]).astype(np.int16)\n","      calendar_win['event_name_1_win'] = calendar_win['event_name_1_win']\n","      grid_df = grid_df.merge(calendar_win, on='d', how='left')\n","      features_columns = features_columns + ['event_name_1_win']\n","      cb_params = cb_params_common\n","    # WI2、CA3、CA4，这三个商店只考虑所有节假日的前两天的效应\n","    else:\n","      calendar_df = pd.read_csv(datasets_path + 'calendar.csv')\n","      calendar_win = calendar_df[['event_name_2','event_name_1','d']]\n","      # 添加特征\n","      event = calendar_df[['event_name_2','event_name_1']].fillna('') \n","      # 上移\n","      event_before1 = pd.DataFrame()\n","      event_up_one = event.shift(-1).fillna('') \n","      event_before1['event_name_2'] = event_up_one['event_name_2'].apply(lambda x: x + '_before1' if x != '' else x)\n","      event_before1['event_name_1'] = event_up_one['event_name_1'].apply(lambda x: x + '_before1' if x != '' else x)\n","      event_before2 = pd.DataFrame()\n","      event_up_two = event.shift(-2).fillna('')   \n","      event_before2['event_name_2'] = event_up_two['event_name_2'].apply(lambda x: x + '_before2' if x != '' else x)\n","      event_before2['event_name_1'] = event_up_two['event_name_1'].apply(lambda x: x + '_before2' if x != '' else x)\n","      event_win = event_before1 + event_before2\n","\n","      calendar_win.drop(columns=['event_name_1','event_name_2'],inplace=True)\n","      # 转换数据类型\n","      calendar_win['event_name_1_win'] = event_win['event_name_1']\n","      calendar_win['event_name_2_win'] = event_win['event_name_2']\n","      calendar_win['d'] = calendar_win['d'].apply(lambda x: x.split('_',2)[1]).astype(np.int16)\n","\n","      grid_df = grid_df.merge(calendar_win, on='d', how='left')\n","      features_columns = features_columns + ['event_name_1_win','event_name_2_win']\n","\n","      cb_params = cb_params_common\n","\n","    # 加入节假日特征之后的features_columns和grid_df\n","    print(features_columns) # CA1：72\n","    print(grid_df.shape) # CA1：(4873639, 75)\n","    ############## cb模型：cat_features必须为整数或字符串，实数值和NaN值应转换为字符串 ##############\n","    categorical_features_indices = ['item_id','dept_id','cat_id','snap_CA','snap_TX','snap_WI',\n","                      'event_name_1','event_type_1','event_name_2','event_type_2',\n","                      'event_name_1_win','event_name_2_win','event_name_1_win_1']\n","    categorical_features_indices = set(features_columns) & set(categorical_features_indices) # 取两个list的交集：set(list1) & set(list2)\n","    for i in categorical_features_indices:\n","      grid_df[i] = grid_df[i].astype('object') # 类别数据的类型要是object\n","      grid_df[i] = grid_df[i].fillna('no') # 注意：cb中不能出现空值，类别列也不可以\n","\n","    train_mask = grid_df['d'] <= END_TRAIN - P_HORIZON # 1<= train <=1941-28 \n","    valid_mask = (grid_df['d'] > (END_TRAIN - P_HORIZON)) & (grid_df['d'] <= END_TRAIN) # 1941-28< valid <=1941\n","    preds_mask = grid_df['d'] > (END_TRAIN - 100) \n","\n","    # 封装cb的训练集和测试集\n","    train_pool = Pool(grid_df[train_mask][features_columns], grid_df[train_mask][TARGET], cat_features = categorical_features_indices) \n","    valid_pool = Pool(grid_df[valid_mask][features_columns], grid_df[valid_mask][TARGET], cat_features = categorical_features_indices)\n","\n","    ## 由于每个商店的节假日效应加的特征不一样，需要分开保存下来\n","    features_columns = pd.Series(features_columns) # 不转化为Series，会出现BUG：'list' object has no attribute 'to_pickle'\n","    features_columns.to_pickle(model_pkl_path +'{}_train_Fea(cb).pkl'.format(store_id)) # 存储训练模型时用的特征\n","\n","    # 构造一个后面预测用的数据集 \n","    grid_df = grid_df[preds_mask].reset_index(drop=True)\n","    keep_cols = [col for col in list(grid_df) if '_tmp_' not in col] # '_tmp_' 滞后 + rolling 比如：rolling_mean_tmp_14_60 去掉了12列\n","    grid_df = grid_df[keep_cols] # CA1：75 - 12 = 63 (390272, 63)  [1842, 1969] 128天\n","    grid_df.to_pickle(model_pkl_path + 'cb_test_{}.pkl'.format(store_id))\n","\n","    seed_everything(SEED)\n","    # 训练模型\n","    cb_model = CatBoostRegressor(**cb_params) \n","    cb_model.fit(train_pool, eval_set = valid_pool) \n","    # 存储模型为二进制文件，下次读取的时候，速度更快\n","    model_name = model_pkl_path + 'cb_model_{}_v{}.bin'.format(store_id, str(VER))\n","    pickle.dump(cb_model, open(model_name, 'wb'))\n","\n","    del grid_df, train_pool, valid_pool, cb_model\n","    gc.collect()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Train WI_1\n","['item_id', 'dept_id', 'cat_id', 'sell_price', 'price_max', 'price_min', 'price_std', 'price_mean', 'price_norm', 'price_nunique', 'item_nunique', 'price_momentum', 'price_momentum_m', 'price_momentum_y', 'event_name_1', 'event_type_1', 'event_name_2', 'event_type_2', 'snap_CA', 'snap_TX', 'snap_WI', 'tm_d', 'tm_w', 'tm_m', 'tm_y', 'tm_wm', 'tm_dw', 'tm_w_end', 'sales_lag_28', 'sales_lag_29', 'sales_lag_30', 'sales_lag_31', 'sales_lag_32', 'sales_lag_33', 'sales_lag_34', 'sales_lag_35', 'sales_lag_36', 'sales_lag_37', 'sales_lag_38', 'sales_lag_39', 'sales_lag_40', 'sales_lag_41', 'sales_lag_42', 'rolling_mean_7', 'rolling_std_7', 'rolling_mean_14', 'rolling_std_14', 'rolling_mean_30', 'rolling_std_30', 'rolling_mean_60', 'rolling_std_60', 'rolling_mean_180', 'rolling_std_180', 'rolling_mean_tmp_1_7', 'rolling_mean_tmp_1_14', 'rolling_mean_tmp_1_30', 'rolling_mean_tmp_1_60', 'rolling_mean_tmp_7_7', 'rolling_mean_tmp_7_14', 'rolling_mean_tmp_7_30', 'rolling_mean_tmp_7_60', 'rolling_mean_tmp_14_7', 'rolling_mean_tmp_14_14', 'rolling_mean_tmp_14_30', 'rolling_mean_tmp_14_60', 'enc_cat_id_mean', 'enc_cat_id_std', 'enc_dept_id_mean', 'enc_dept_id_std', 'enc_item_id_mean', 'enc_item_id_std', 'event_name_1_win', 'event_name_2_win']\n","(4646139, 76)\n","0:\tlearn: 2.7929847\ttest: 2.7390440\tbest: 2.7390440 (0)\ttotal: 1.15s\tremaining: 29m 10s\n","100:\tlearn: 1.6823721\ttest: 1.6139829\tbest: 1.6139829 (100)\ttotal: 1m 42s\tremaining: 24m 4s\n","200:\tlearn: 1.6619000\ttest: 1.6056937\tbest: 1.6056937 (200)\ttotal: 3m 26s\tremaining: 22m 39s\n","300:\tlearn: 1.6496434\ttest: 1.6022949\tbest: 1.6022733 (299)\ttotal: 5m 6s\tremaining: 20m 43s\n","400:\tlearn: 1.6406870\ttest: 1.5996752\tbest: 1.5996752 (400)\ttotal: 6m 43s\tremaining: 18m 48s\n","500:\tlearn: 1.6333468\ttest: 1.5976156\tbest: 1.5976131 (499)\ttotal: 8m 25s\tremaining: 17m 12s\n","600:\tlearn: 1.6271797\ttest: 1.5960662\tbest: 1.5960382 (597)\ttotal: 10m 5s\tremaining: 15m 29s\n","700:\tlearn: 1.6209679\ttest: 1.5950418\tbest: 1.5950137 (693)\ttotal: 11m 47s\tremaining: 13m 50s\n","800:\tlearn: 1.6158999\ttest: 1.5946207\tbest: 1.5946178 (797)\ttotal: 13m 26s\tremaining: 12m 8s\n","900:\tlearn: 1.6107727\ttest: 1.5939893\tbest: 1.5938449 (889)\ttotal: 15m 8s\tremaining: 10m 28s\n","1000:\tlearn: 1.6064167\ttest: 1.5940291\tbest: 1.5937336 (959)\ttotal: 16m 49s\tremaining: 8m 47s\n","Stopped by overfitting detector  (50 iterations wait)\n","\n","bestTest = 1.593733598\n","bestIteration = 959\n","\n","Shrink model to first 960 iterations.\n","Train WI_2\n","['item_id', 'dept_id', 'cat_id', 'sell_price', 'price_max', 'price_min', 'price_std', 'price_mean', 'price_norm', 'price_nunique', 'item_nunique', 'price_momentum', 'price_momentum_m', 'price_momentum_y', 'event_name_1', 'event_type_1', 'event_name_2', 'event_type_2', 'snap_CA', 'snap_TX', 'snap_WI', 'tm_d', 'tm_w', 'tm_m', 'tm_y', 'tm_wm', 'tm_dw', 'tm_w_end', 'sales_lag_28', 'sales_lag_29', 'sales_lag_30', 'sales_lag_31', 'sales_lag_32', 'sales_lag_33', 'sales_lag_34', 'sales_lag_35', 'sales_lag_36', 'sales_lag_37', 'sales_lag_38', 'sales_lag_39', 'sales_lag_40', 'sales_lag_41', 'sales_lag_42', 'rolling_mean_7', 'rolling_std_7', 'rolling_mean_14', 'rolling_std_14', 'rolling_mean_30', 'rolling_std_30', 'rolling_mean_60', 'rolling_std_60', 'rolling_mean_180', 'rolling_std_180', 'rolling_mean_tmp_1_7', 'rolling_mean_tmp_1_14', 'rolling_mean_tmp_1_30', 'rolling_mean_tmp_1_60', 'rolling_mean_tmp_7_7', 'rolling_mean_tmp_7_14', 'rolling_mean_tmp_7_30', 'rolling_mean_tmp_7_60', 'rolling_mean_tmp_14_7', 'rolling_mean_tmp_14_14', 'rolling_mean_tmp_14_30', 'rolling_mean_tmp_14_60', 'enc_cat_id_mean', 'enc_cat_id_std', 'enc_dept_id_mean', 'enc_dept_id_std', 'enc_item_id_mean', 'enc_item_id_std', 'event_name_1_win', 'event_name_2_win']\n","(4731952, 76)\n","0:\tlearn: 4.3179691\ttest: 4.9405603\tbest: 4.9405603 (0)\ttotal: 1.26s\tremaining: 32m\n","100:\tlearn: 2.6262621\ttest: 2.7165921\tbest: 2.7165921 (100)\ttotal: 1m 36s\tremaining: 22m 41s\n","200:\tlearn: 2.5783403\ttest: 2.6974719\tbest: 2.6974538 (199)\ttotal: 3m 14s\tremaining: 21m 19s\n","300:\tlearn: 2.5426458\ttest: 2.6903069\tbest: 2.6893191 (287)\ttotal: 4m 48s\tremaining: 19m 32s\n","400:\tlearn: 2.5144375\ttest: 2.6875682\tbest: 2.6871489 (359)\ttotal: 6m 20s\tremaining: 17m 44s\n","Stopped by overfitting detector  (50 iterations wait)\n","\n","bestTest = 2.68714895\n","bestIteration = 359\n","\n","Shrink model to first 360 iterations.\n","Train WI_3\n","['item_id', 'dept_id', 'cat_id', 'sell_price', 'price_max', 'price_min', 'price_std', 'price_mean', 'price_norm', 'price_nunique', 'item_nunique', 'price_momentum', 'price_momentum_m', 'price_momentum_y', 'event_name_1', 'event_type_1', 'event_name_2', 'event_type_2', 'snap_CA', 'snap_TX', 'snap_WI', 'tm_d', 'tm_w', 'tm_m', 'tm_y', 'tm_wm', 'tm_dw', 'tm_w_end', 'sales_lag_28', 'sales_lag_29', 'sales_lag_30', 'sales_lag_31', 'sales_lag_32', 'sales_lag_33', 'sales_lag_34', 'sales_lag_35', 'sales_lag_36', 'sales_lag_37', 'sales_lag_38', 'sales_lag_39', 'sales_lag_40', 'sales_lag_41', 'sales_lag_42', 'rolling_mean_7', 'rolling_std_7', 'rolling_mean_14', 'rolling_std_14', 'rolling_mean_30', 'rolling_std_30', 'rolling_mean_60', 'rolling_std_60', 'rolling_mean_180', 'rolling_std_180', 'rolling_mean_tmp_1_7', 'rolling_mean_tmp_1_14', 'rolling_mean_tmp_1_30', 'rolling_mean_tmp_1_60', 'rolling_mean_tmp_7_7', 'rolling_mean_tmp_7_14', 'rolling_mean_tmp_7_30', 'rolling_mean_tmp_7_60', 'rolling_mean_tmp_14_7', 'rolling_mean_tmp_14_14', 'rolling_mean_tmp_14_30', 'rolling_mean_tmp_14_60', 'enc_cat_id_mean', 'enc_cat_id_std', 'enc_dept_id_mean', 'enc_dept_id_std', 'enc_item_id_mean', 'enc_item_id_std', 'event_name_1_win']\n","(4857413, 75)\n","0:\tlearn: 4.4256104\ttest: 3.7917344\tbest: 3.7917344 (0)\ttotal: 1.26s\tremaining: 31m 53s\n","100:\tlearn: 2.2973051\ttest: 1.9220290\tbest: 1.9220290 (100)\ttotal: 1m 30s\tremaining: 21m 20s\n","200:\tlearn: 2.2440856\ttest: 1.9060196\tbest: 1.9060196 (200)\ttotal: 3m 3s\tremaining: 20m 7s\n","300:\tlearn: 2.2100093\ttest: 1.8988440\tbest: 1.8988440 (300)\ttotal: 4m 39s\tremaining: 18m 54s\n","400:\tlearn: 2.1869516\ttest: 1.8936418\tbest: 1.8935752 (398)\ttotal: 6m 14s\tremaining: 17m 28s\n","500:\tlearn: 2.1652103\ttest: 1.8931016\tbest: 1.8926753 (489)\ttotal: 7m 45s\tremaining: 15m 51s\n","600:\tlearn: 2.1452095\ttest: 1.8896099\tbest: 1.8895300 (597)\ttotal: 9m 17s\tremaining: 14m 16s\n","700:\tlearn: 2.1273247\ttest: 1.8880982\tbest: 1.8880982 (700)\ttotal: 10m 48s\tremaining: 12m 41s\n","800:\tlearn: 2.1132833\ttest: 1.8874434\tbest: 1.8872666 (789)\ttotal: 12m 18s\tremaining: 11m 6s\n","900:\tlearn: 2.1005621\ttest: 1.8858540\tbest: 1.8857537 (889)\ttotal: 13m 51s\tremaining: 9m 34s\n","1000:\tlearn: 2.0887928\ttest: 1.8844400\tbest: 1.8843662 (984)\ttotal: 15m 23s\tremaining: 8m 2s\n","1100:\tlearn: 2.0775935\ttest: 1.8828652\tbest: 1.8826900 (1062)\ttotal: 16m 57s\tremaining: 6m 30s\n","Stopped by overfitting detector  (50 iterations wait)\n","\n","bestTest = 1.882689991\n","bestIteration = 1062\n","\n","Shrink model to first 1063 iterations.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"P82uH2Fe5oFr","colab_type":"code","colab":{}},"source":["### 查看某个商店由模型训练得到的特征重要度\n","model_bin = 'cb_model_{}_v{}.bin'.format('CA_1', str(VER))\n","if USE_AUX:\n","  model_path = Model_path + model_bin\n","  cb_model = pickle.load(open(model_path, 'rb'))\n","# 训练结束后，通过 model.feature_importances_ 属性，可以拿到这些特征的重要程度数据，特征的重要性程度可以帮助我们分析出一些有用的信息。\n","# 执行下面的代码，可以拿到特征重要程度的可视化结构。\n","import matplotlib.pyplot as plt \n","plt.style.use('fivethirtyeight') # 这个风格是白底带网格的\n","fea_ = cb_model.feature_importances_ # <class 'numpy.ndarray'>\n","fea_name = cb_model.feature_names_ # <class 'numpy.ndarray'>\n","plt.figure(figsize=(15,18))\n","plt.barh(fea_name, fea_) # 名字作为x，重要值作为y\n","plt.show()\n","# 使用matplotlib.pyplot.barh()函数来绘制水平型的条形图，注意：与bar()函数最大的不同是X轴和Y轴是颠倒过来的\n","# 选择使用不同的作图主题，使用 style.use() 函数即可"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"K-6G3-elfFma","colab_type":"text"},"source":["## 预测"]},{"cell_type":"code","metadata":{"id":"Ua8fJmu1c-qi","colab_type":"code","colab":{}},"source":["## 如果前面训练断开了，方便下面预测直接使用\n","CA1 = ['item_id', 'dept_id', 'cat_id', 'sell_price', 'price_max', 'price_min', 'price_std', 'price_mean', 'price_norm', 'price_nunique', 'item_nunique', 'price_momentum', 'price_momentum_m', 'price_momentum_y', 'event_name_1', 'event_type_1', 'event_name_2', 'event_type_2', 'snap_CA', 'snap_TX', 'snap_WI', 'tm_d', 'tm_w', 'tm_m', 'tm_y', 'tm_wm', 'tm_dw', 'tm_w_end', 'sales_lag_28', 'sales_lag_29', 'sales_lag_30', 'sales_lag_31', 'sales_lag_32', 'sales_lag_33', 'sales_lag_34', 'sales_lag_35', 'sales_lag_36', 'sales_lag_37', 'sales_lag_38', 'sales_lag_39', 'sales_lag_40', 'sales_lag_41', 'sales_lag_42', 'rolling_mean_7', 'rolling_std_7', 'rolling_mean_14', 'rolling_std_14', 'rolling_mean_30', 'rolling_std_30', 'rolling_mean_60', 'rolling_std_60', 'rolling_mean_180', 'rolling_std_180', 'rolling_mean_tmp_1_7', 'rolling_mean_tmp_1_14', 'rolling_mean_tmp_1_30', 'rolling_mean_tmp_1_60', 'rolling_mean_tmp_7_7', 'rolling_mean_tmp_7_14', 'rolling_mean_tmp_7_30', 'rolling_mean_tmp_7_60', 'rolling_mean_tmp_14_7', 'rolling_mean_tmp_14_14', 'rolling_mean_tmp_14_30', 'rolling_mean_tmp_14_60', 'enc_cat_id_mean', 'enc_cat_id_std', 'enc_dept_id_mean', 'enc_dept_id_std', 'enc_item_id_mean', 'enc_item_id_std', 'event_name_1_win']\n","CA1 = pd.Series(CA1) ## 转化为Series，才能用to_pickle()\n","CA1.to_pickle(model_pkl_path +'CA_1_train_Fea.pkl')\n","\n","CA2 = ['item_id', 'dept_id', 'cat_id', 'sell_price', 'price_max', 'price_min', 'price_std', 'price_mean', 'price_norm', 'price_nunique', 'item_nunique', 'price_momentum', 'price_momentum_m', 'price_momentum_y', 'event_name_1', 'event_type_1', 'event_name_2', 'event_type_2', 'snap_CA', 'snap_TX', 'snap_WI', 'tm_d', 'tm_w', 'tm_m', 'tm_y', 'tm_wm', 'tm_dw', 'tm_w_end', 'sales_lag_28', 'sales_lag_29', 'sales_lag_30', 'sales_lag_31', 'sales_lag_32', 'sales_lag_33', 'sales_lag_34', 'sales_lag_35', 'sales_lag_36', 'sales_lag_37', 'sales_lag_38', 'sales_lag_39', 'sales_lag_40', 'sales_lag_41', 'sales_lag_42', 'rolling_mean_7', 'rolling_std_7', 'rolling_mean_14', 'rolling_std_14', 'rolling_mean_30', 'rolling_std_30', 'rolling_mean_60', 'rolling_std_60', 'rolling_mean_180', 'rolling_std_180', 'rolling_mean_tmp_1_7', 'rolling_mean_tmp_1_14', 'rolling_mean_tmp_1_30', 'rolling_mean_tmp_1_60', 'rolling_mean_tmp_7_7', 'rolling_mean_tmp_7_14', 'rolling_mean_tmp_7_30', 'rolling_mean_tmp_7_60', 'rolling_mean_tmp_14_7', 'rolling_mean_tmp_14_14', 'rolling_mean_tmp_14_30', 'rolling_mean_tmp_14_60', 'enc_cat_id_mean', 'enc_cat_id_std', 'enc_dept_id_mean', 'enc_dept_id_std', 'enc_item_id_mean', 'enc_item_id_std', 'event_name_1_win']\n","CA2 = pd.Series(CA2)\n","CA2.to_pickle(model_pkl_path +'CA_2_train_Fea.pkl')\n","\n","CA3 = ['item_id', 'dept_id', 'cat_id', 'sell_price', 'price_max', 'price_min', 'price_std', 'price_mean', 'price_norm', 'price_nunique', 'item_nunique', 'price_momentum', 'price_momentum_m', 'price_momentum_y', 'event_name_1', 'event_type_1', 'event_name_2', 'event_type_2', 'snap_CA', 'snap_TX', 'snap_WI', 'tm_d', 'tm_w', 'tm_m', 'tm_y', 'tm_wm', 'tm_dw', 'tm_w_end', 'sales_lag_28', 'sales_lag_29', 'sales_lag_30', 'sales_lag_31', 'sales_lag_32', 'sales_lag_33', 'sales_lag_34', 'sales_lag_35', 'sales_lag_36', 'sales_lag_37', 'sales_lag_38', 'sales_lag_39', 'sales_lag_40', 'sales_lag_41', 'sales_lag_42', 'rolling_mean_7', 'rolling_std_7', 'rolling_mean_14', 'rolling_std_14', 'rolling_mean_30', 'rolling_std_30', 'rolling_mean_60', 'rolling_std_60', 'rolling_mean_180', 'rolling_std_180', 'rolling_mean_tmp_1_7', 'rolling_mean_tmp_1_14', 'rolling_mean_tmp_1_30', 'rolling_mean_tmp_1_60', 'rolling_mean_tmp_7_7', 'rolling_mean_tmp_7_14', 'rolling_mean_tmp_7_30', 'rolling_mean_tmp_7_60', 'rolling_mean_tmp_14_7', 'rolling_mean_tmp_14_14', 'rolling_mean_tmp_14_30', 'rolling_mean_tmp_14_60', 'enc_cat_id_mean', 'enc_cat_id_std', 'enc_dept_id_mean', 'enc_dept_id_std', 'enc_item_id_mean', 'enc_item_id_std', 'event_name_1_win', 'event_name_2_win']\n","CA3 = pd.Series(CA3)\n","CA3.to_pickle(model_pkl_path +'CA_3_train_Fea.pkl')\n","\n","CA4 = ['item_id', 'dept_id', 'cat_id', 'sell_price', 'price_max', 'price_min', 'price_std', 'price_mean', 'price_norm', 'price_nunique', 'item_nunique', 'price_momentum', 'price_momentum_m', 'price_momentum_y', 'event_name_1', 'event_type_1', 'event_name_2', 'event_type_2', 'snap_CA', 'snap_TX', 'snap_WI', 'tm_d', 'tm_w', 'tm_m', 'tm_y', 'tm_wm', 'tm_dw', 'tm_w_end', 'sales_lag_28', 'sales_lag_29', 'sales_lag_30', 'sales_lag_31', 'sales_lag_32', 'sales_lag_33', 'sales_lag_34', 'sales_lag_35', 'sales_lag_36', 'sales_lag_37', 'sales_lag_38', 'sales_lag_39', 'sales_lag_40', 'sales_lag_41', 'sales_lag_42', 'rolling_mean_7', 'rolling_std_7', 'rolling_mean_14', 'rolling_std_14', 'rolling_mean_30', 'rolling_std_30', 'rolling_mean_60', 'rolling_std_60', 'rolling_mean_180', 'rolling_std_180', 'rolling_mean_tmp_1_7', 'rolling_mean_tmp_1_14', 'rolling_mean_tmp_1_30', 'rolling_mean_tmp_1_60', 'rolling_mean_tmp_7_7', 'rolling_mean_tmp_7_14', 'rolling_mean_tmp_7_30', 'rolling_mean_tmp_7_60', 'rolling_mean_tmp_14_7', 'rolling_mean_tmp_14_14', 'rolling_mean_tmp_14_30', 'rolling_mean_tmp_14_60', 'enc_cat_id_mean', 'enc_cat_id_std', 'enc_dept_id_mean', 'enc_dept_id_std', 'enc_item_id_mean', 'enc_item_id_std', 'event_name_1_win', 'event_name_2_win']\n","CA4 = pd.Series(CA4)\n","CA4.to_pickle(model_pkl_path +'CA_4_train_Fea.pkl')\n","\n","TX1 = ['item_id', 'dept_id', 'cat_id', 'sell_price', 'price_max', 'price_min', 'price_std', 'price_mean', 'price_norm', 'price_nunique', 'item_nunique', 'price_momentum', 'price_momentum_m', 'price_momentum_y', 'event_name_1', 'event_type_1', 'event_name_2', 'event_type_2', 'snap_CA', 'snap_TX', 'snap_WI', 'tm_d', 'tm_w', 'tm_m', 'tm_y', 'tm_wm', 'tm_dw', 'tm_w_end', 'sales_lag_28', 'sales_lag_29', 'sales_lag_30', 'sales_lag_31', 'sales_lag_32', 'sales_lag_33', 'sales_lag_34', 'sales_lag_35', 'sales_lag_36', 'sales_lag_37', 'sales_lag_38', 'sales_lag_39', 'sales_lag_40', 'sales_lag_41', 'sales_lag_42', 'rolling_mean_7', 'rolling_std_7', 'rolling_mean_14', 'rolling_std_14', 'rolling_mean_30', 'rolling_std_30', 'rolling_mean_60', 'rolling_std_60', 'rolling_mean_180', 'rolling_std_180', 'rolling_mean_tmp_1_7', 'rolling_mean_tmp_1_14', 'rolling_mean_tmp_1_30', 'rolling_mean_tmp_1_60', 'rolling_mean_tmp_7_7', 'rolling_mean_tmp_7_14', 'rolling_mean_tmp_7_30', 'rolling_mean_tmp_7_60', 'rolling_mean_tmp_14_7', 'rolling_mean_tmp_14_14', 'rolling_mean_tmp_14_30', 'rolling_mean_tmp_14_60', 'enc_cat_id_mean', 'enc_cat_id_std', 'enc_dept_id_mean', 'enc_dept_id_std', 'enc_item_id_mean', 'enc_item_id_std', 'event_name_1_win', 'event_name_2_win', 'event_name_1_win_1']\n","TX1 = pd.Series(TX1)\n","TX1.to_pickle(model_pkl_path +'TX_1_train_Fea.pkl')\n","\n","TX2 = ['item_id', 'dept_id', 'cat_id', 'sell_price', 'price_max', 'price_min', 'price_std', 'price_mean', 'price_norm', 'price_nunique', 'item_nunique', 'price_momentum', 'price_momentum_m', 'price_momentum_y', 'event_name_1', 'event_type_1', 'event_name_2', 'event_type_2', 'snap_CA', 'snap_TX', 'snap_WI', 'tm_d', 'tm_w', 'tm_m', 'tm_y', 'tm_wm', 'tm_dw', 'tm_w_end', 'sales_lag_28', 'sales_lag_29', 'sales_lag_30', 'sales_lag_31', 'sales_lag_32', 'sales_lag_33', 'sales_lag_34', 'sales_lag_35', 'sales_lag_36', 'sales_lag_37', 'sales_lag_38', 'sales_lag_39', 'sales_lag_40', 'sales_lag_41', 'sales_lag_42', 'rolling_mean_7', 'rolling_std_7', 'rolling_mean_14', 'rolling_std_14', 'rolling_mean_30', 'rolling_std_30', 'rolling_mean_60', 'rolling_std_60', 'rolling_mean_180', 'rolling_std_180', 'rolling_mean_tmp_1_7', 'rolling_mean_tmp_1_14', 'rolling_mean_tmp_1_30', 'rolling_mean_tmp_1_60', 'rolling_mean_tmp_7_7', 'rolling_mean_tmp_7_14', 'rolling_mean_tmp_7_30', 'rolling_mean_tmp_7_60', 'rolling_mean_tmp_14_7', 'rolling_mean_tmp_14_14', 'rolling_mean_tmp_14_30', 'rolling_mean_tmp_14_60', 'enc_cat_id_mean', 'enc_cat_id_std', 'enc_dept_id_mean', 'enc_dept_id_std', 'enc_item_id_mean', 'enc_item_id_std', 'event_name_1_win']\n","TX2 = pd.Series(TX2)\n","TX2.to_pickle(model_pkl_path +'TX_2_train_Fea.pkl')\n","\n","TX3 = ['item_id', 'dept_id', 'cat_id', 'sell_price', 'price_max', 'price_min', 'price_std', 'price_mean', 'price_norm', 'price_nunique', 'item_nunique', 'price_momentum', 'price_momentum_m', 'price_momentum_y', 'event_name_1', 'event_type_1', 'event_name_2', 'event_type_2', 'snap_CA', 'snap_TX', 'snap_WI', 'tm_d', 'tm_w', 'tm_m', 'tm_y', 'tm_wm', 'tm_dw', 'tm_w_end', 'sales_lag_28', 'sales_lag_29', 'sales_lag_30', 'sales_lag_31', 'sales_lag_32', 'sales_lag_33', 'sales_lag_34', 'sales_lag_35', 'sales_lag_36', 'sales_lag_37', 'sales_lag_38', 'sales_lag_39', 'sales_lag_40', 'sales_lag_41', 'sales_lag_42', 'rolling_mean_7', 'rolling_std_7', 'rolling_mean_14', 'rolling_std_14', 'rolling_mean_30', 'rolling_std_30', 'rolling_mean_60', 'rolling_std_60', 'rolling_mean_180', 'rolling_std_180', 'rolling_mean_tmp_1_7', 'rolling_mean_tmp_1_14', 'rolling_mean_tmp_1_30', 'rolling_mean_tmp_1_60', 'rolling_mean_tmp_7_7', 'rolling_mean_tmp_7_14', 'rolling_mean_tmp_7_30', 'rolling_mean_tmp_7_60', 'rolling_mean_tmp_14_7', 'rolling_mean_tmp_14_14', 'rolling_mean_tmp_14_30', 'rolling_mean_tmp_14_60', 'enc_cat_id_mean', 'enc_cat_id_std', 'enc_dept_id_mean', 'enc_dept_id_std', 'enc_item_id_mean', 'enc_item_id_std', 'event_name_1_win']\n","TX3 = pd.Series(TX3)\n","TX3.to_pickle(model_pkl_path +'TX_3_train_Fea.pkl')\n","\n","WI1 = ['item_id', 'dept_id', 'cat_id', 'sell_price', 'price_max', 'price_min', 'price_std', 'price_mean', 'price_norm', 'price_nunique', 'item_nunique', 'price_momentum', 'price_momentum_m', 'price_momentum_y', 'event_name_1', 'event_type_1', 'event_name_2', 'event_type_2', 'snap_CA', 'snap_TX', 'snap_WI', 'tm_d', 'tm_w', 'tm_m', 'tm_y', 'tm_wm', 'tm_dw', 'tm_w_end', 'sales_lag_28', 'sales_lag_29', 'sales_lag_30', 'sales_lag_31', 'sales_lag_32', 'sales_lag_33', 'sales_lag_34', 'sales_lag_35', 'sales_lag_36', 'sales_lag_37', 'sales_lag_38', 'sales_lag_39', 'sales_lag_40', 'sales_lag_41', 'sales_lag_42', 'rolling_mean_7', 'rolling_std_7', 'rolling_mean_14', 'rolling_std_14', 'rolling_mean_30', 'rolling_std_30', 'rolling_mean_60', 'rolling_std_60', 'rolling_mean_180', 'rolling_std_180', 'rolling_mean_tmp_1_7', 'rolling_mean_tmp_1_14', 'rolling_mean_tmp_1_30', 'rolling_mean_tmp_1_60', 'rolling_mean_tmp_7_7', 'rolling_mean_tmp_7_14', 'rolling_mean_tmp_7_30', 'rolling_mean_tmp_7_60', 'rolling_mean_tmp_14_7', 'rolling_mean_tmp_14_14', 'rolling_mean_tmp_14_30', 'rolling_mean_tmp_14_60', 'enc_cat_id_mean', 'enc_cat_id_std', 'enc_dept_id_mean', 'enc_dept_id_std', 'enc_item_id_mean', 'enc_item_id_std', 'event_name_1_win', 'event_name_2_win']\n","WI1 = pd.Series(WI1)\n","WI1.to_pickle(model_pkl_path +'WI_1_train_Fea.pkl')\n","\n","WI2 = ['item_id', 'dept_id', 'cat_id', 'sell_price', 'price_max', 'price_min', 'price_std', 'price_mean', 'price_norm', 'price_nunique', 'item_nunique', 'price_momentum', 'price_momentum_m', 'price_momentum_y', 'event_name_1', 'event_type_1', 'event_name_2', 'event_type_2', 'snap_CA', 'snap_TX', 'snap_WI', 'tm_d', 'tm_w', 'tm_m', 'tm_y', 'tm_wm', 'tm_dw', 'tm_w_end', 'sales_lag_28', 'sales_lag_29', 'sales_lag_30', 'sales_lag_31', 'sales_lag_32', 'sales_lag_33', 'sales_lag_34', 'sales_lag_35', 'sales_lag_36', 'sales_lag_37', 'sales_lag_38', 'sales_lag_39', 'sales_lag_40', 'sales_lag_41', 'sales_lag_42', 'rolling_mean_7', 'rolling_std_7', 'rolling_mean_14', 'rolling_std_14', 'rolling_mean_30', 'rolling_std_30', 'rolling_mean_60', 'rolling_std_60', 'rolling_mean_180', 'rolling_std_180', 'rolling_mean_tmp_1_7', 'rolling_mean_tmp_1_14', 'rolling_mean_tmp_1_30', 'rolling_mean_tmp_1_60', 'rolling_mean_tmp_7_7', 'rolling_mean_tmp_7_14', 'rolling_mean_tmp_7_30', 'rolling_mean_tmp_7_60', 'rolling_mean_tmp_14_7', 'rolling_mean_tmp_14_14', 'rolling_mean_tmp_14_30', 'rolling_mean_tmp_14_60', 'enc_cat_id_mean', 'enc_cat_id_std', 'enc_dept_id_mean', 'enc_dept_id_std', 'enc_item_id_mean', 'enc_item_id_std', 'event_name_1_win', 'event_name_2_win']\n","WI2 = pd.Series(WI2)\n","WI2.to_pickle(model_pkl_path +'WI_2_train_Fea.pkl')\n","\n","WI3 = ['item_id', 'dept_id', 'cat_id', 'sell_price', 'price_max', 'price_min', 'price_std', 'price_mean', 'price_norm', 'price_nunique', 'item_nunique', 'price_momentum', 'price_momentum_m', 'price_momentum_y', 'event_name_1', 'event_type_1', 'event_name_2', 'event_type_2', 'snap_CA', 'snap_TX', 'snap_WI', 'tm_d', 'tm_w', 'tm_m', 'tm_y', 'tm_wm', 'tm_dw', 'tm_w_end', 'sales_lag_28', 'sales_lag_29', 'sales_lag_30', 'sales_lag_31', 'sales_lag_32', 'sales_lag_33', 'sales_lag_34', 'sales_lag_35', 'sales_lag_36', 'sales_lag_37', 'sales_lag_38', 'sales_lag_39', 'sales_lag_40', 'sales_lag_41', 'sales_lag_42', 'rolling_mean_7', 'rolling_std_7', 'rolling_mean_14', 'rolling_std_14', 'rolling_mean_30', 'rolling_std_30', 'rolling_mean_60', 'rolling_std_60', 'rolling_mean_180', 'rolling_std_180', 'rolling_mean_tmp_1_7', 'rolling_mean_tmp_1_14', 'rolling_mean_tmp_1_30', 'rolling_mean_tmp_1_60', 'rolling_mean_tmp_7_7', 'rolling_mean_tmp_7_14', 'rolling_mean_tmp_7_30', 'rolling_mean_tmp_7_60', 'rolling_mean_tmp_14_7', 'rolling_mean_tmp_14_14', 'rolling_mean_tmp_14_30', 'rolling_mean_tmp_14_60', 'enc_cat_id_mean', 'enc_cat_id_std', 'enc_dept_id_mean', 'enc_dept_id_std', 'enc_item_id_mean', 'enc_item_id_std', 'event_name_1_win']\n","WI3 = pd.Series(WI3)\n","WI3.to_pickle(model_pkl_path +'WI_3_train_Fea.pkl')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"bV36FmMfPuOR","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1594257237332,"user_tz":-480,"elapsed":2436201,"user":{"displayName":"余凯","photoUrl":"","userId":"13334016005065607071"}},"outputId":"8a9cb8ab-4872-4137-a5dd-9f3f944d9cad"},"source":["USE_AUX = True\n","END_TRAIN = 1941\n","all_preds = pd.DataFrame()\n","STORES_IDS = ['CA_1','CA_2','CA_3','CA_4','TX_1','TX_2','TX_3','WI_1','WI_2','WI_3']\n","base_test = get_base_test() \n","# 3902720 rows × 66 columns 62 + 4（event_name_1_win、store_id、event_name_2_win、event_name_1_win_1）\n","# 记住：后面这个特征是新加的，原来只有62 + 12(lag+rolling) = 72\n","main_time = time.time()\n","\n","for PREDICT_DAY in range(1,29):    \n","  print('Predict | Day:', PREDICT_DAY)\n","  start_time = time.time() \n","  grid_df = base_test.copy() \n","  grid_df = pd.concat([grid_df, df_parallelize_run(make_lag_roll, ROLS_SPLIT)], axis=1) \n","\n","  for store_id in STORES_IDS:\n","    model_bin = 'cb_model_{}_v{}.bin'.format(store_id, str(VER))\n","    if USE_AUX:\n","      model_path = model_pkl_path + model_bin\n","    cb_model = pickle.load(open(model_path, 'rb')) # 读取训练好的模型\n","    MODEL_FEATURES = pd.read_pickle(model_pkl_path +'{}_train_Fea(cb).pkl'.format(store_id)).tolist() \n","    categorical_features_indices = ['item_id','dept_id','cat_id','snap_CA','snap_TX','snap_WI',\n","                      'event_name_1','event_type_1','event_name_2','event_type_2',\n","                      'event_name_1_win','event_name_2_win','event_name_1_win_1']\n","    categorical_features_indices = set(MODEL_FEATURES) & set(categorical_features_indices) \n","    for i in categorical_features_indices:\n","      grid_df[i] = grid_df[i].astype('object')\n","      grid_df[i] = grid_df[i].fillna('no') \n","    ## 某一天\n","    day_mask = base_test['d'] == (END_TRAIN + PREDICT_DAY) # 1942、1943、...、1969\n","    ## 某个店\n","    store_mask = base_test['store_id'] == store_id\n","    ## 某一天某个店\n","    mask = (day_mask) & (store_mask)\n","    ## 预测某商店在 END_TRAIN + PREDICT_DAY 这一天商品的销量\n","    base_test[TARGET][mask] = cb_model.predict(grid_df[mask][MODEL_FEATURES])\n","    ## 这里当时出现了一个BUG，说训练集和验证集的类别变量跟测试集不一致，然后我查看一下grid_df.info()发现\n","    ## 里面的节假日效应在构造测试集的时候没有转化为\"category\"，然后我就在get_base_test()里面把它们转化为类别变量，这样就可以预测了\n","\n","  temp_df = base_test[day_mask][['id',TARGET]]\n","  temp_df.columns = ['id', 'F' + str(PREDICT_DAY)]\n","  if 'id' in list(all_preds):\n","    all_preds = all_preds.merge(temp_df, on=['id'], how='left')\n","  else:\n","    all_preds = temp_df.copy()\n","      \n","  print('#'*10, ' %0.2f min round |' % ((time.time() - start_time) / 60),\n","          ' %0.2f min total |' % ((time.time() - main_time) / 60),\n","          ' %0.2f day sales |' % (temp_df['F' + str(PREDICT_DAY)].sum()))\n","  del temp_df\n","    \n","all_preds = all_preds.reset_index(drop=True)\n","all_preds.to_csv(pred_path + 'per_store_pred(cb).csv',index=False)\n","\n","# 用于生成提交预测的文件\n","submission = pd.read_csv(datasets_path + 'sample_submission.csv')[['id']] # [[]] 返回DataFrame [] 返回Series\n","submission = submission.merge(all_preds, on=['id'], how='left').fillna(0)\n","submission.to_csv(sub_path + 'submission_by_stores(cb).csv'), index=False) "],"execution_count":null,"outputs":[{"output_type":"stream","text":["Predict | Day: 1\n","##########  1.57 min round |  1.57 min total |  38796.23 day sales |\n","Predict | Day: 2\n","##########  1.45 min round |  3.02 min total |  36175.43 day sales |\n","Predict | Day: 3\n","##########  1.45 min round |  4.47 min total |  35815.20 day sales |\n","Predict | Day: 4\n","##########  1.44 min round |  5.91 min total |  36006.28 day sales |\n","Predict | Day: 5\n","##########  1.45 min round |  7.36 min total |  41032.78 day sales |\n","Predict | Day: 6\n","##########  1.44 min round |  8.80 min total |  49654.95 day sales |\n","Predict | Day: 7\n","##########  1.42 min round |  10.22 min total |  49233.42 day sales |\n","Predict | Day: 8\n","##########  1.43 min round |  11.66 min total |  40840.35 day sales |\n","Predict | Day: 9\n","##########  1.44 min round |  13.09 min total |  39064.69 day sales |\n","Predict | Day: 10\n","##########  1.43 min round |  14.52 min total |  42542.58 day sales |\n","Predict | Day: 11\n","##########  1.43 min round |  15.95 min total |  42915.36 day sales |\n","Predict | Day: 12\n","##########  1.44 min round |  17.39 min total |  49945.42 day sales |\n","Predict | Day: 13\n","##########  1.43 min round |  18.82 min total |  54082.58 day sales |\n","Predict | Day: 14\n","##########  1.43 min round |  20.25 min total |  55928.30 day sales |\n","Predict | Day: 15\n","##########  1.43 min round |  21.68 min total |  45488.01 day sales |\n","Predict | Day: 16\n","##########  1.43 min round |  23.11 min total |  41082.15 day sales |\n","Predict | Day: 17\n","##########  1.42 min round |  24.54 min total |  41302.39 day sales |\n","Predict | Day: 18\n","##########  1.42 min round |  25.96 min total |  42701.84 day sales |\n","Predict | Day: 19\n","##########  1.43 min round |  27.38 min total |  45075.57 day sales |\n","Predict | Day: 20\n","##########  1.42 min round |  28.81 min total |  56060.84 day sales |\n","Predict | Day: 21\n","##########  1.41 min round |  30.22 min total |  56596.91 day sales |\n","Predict | Day: 22\n","##########  1.42 min round |  31.64 min total |  42991.50 day sales |\n","Predict | Day: 23\n","##########  1.42 min round |  33.06 min total |  41002.72 day sales |\n","Predict | Day: 24\n","##########  1.41 min round |  34.48 min total |  41842.79 day sales |\n","Predict | Day: 25\n","##########  1.42 min round |  35.90 min total |  39200.76 day sales |\n","Predict | Day: 26\n","##########  1.44 min round |  37.34 min total |  45371.38 day sales |\n","Predict | Day: 27\n","##########  1.44 min round |  38.77 min total |  53676.36 day sales |\n","Predict | Day: 28\n","##########  1.44 min round |  40.21 min total |  50854.61 day sales |\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"tc4W3-XD6sNM","colab_type":"text"},"source":["## 某个商店进行贝叶斯调参"]},{"cell_type":"code","metadata":{"id":"VXHlTryV7POW","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":199},"outputId":"ab918139-c516-42c4-b66b-a6f1951a6dae"},"source":["!pip install bayesian-optimization\n","from bayes_opt import BayesianOptimization\n","def rmse(y, y_pred):\n","  return np.sqrt(np.mean(np.square(y - y_pred)))\n","\n","store_id = ['CA_1']\n","TARGET = 'sales'\n","day = 1941\n","grid_df, features_columns = get_data_by_store(store_id)\n","df = grid_df[grid_df['d'] <= day]\n","del grid_df, features_columns\n","\n","MODEL_FEATURES = pd.read_pickle(model_pkl_path +'{}_train_Fea(cb).pkl'.format(store_id)).tolist() \n","\n","# 1000到1941-28-28 作为训练集\n","train_mask = (df['d'] >= 1000) & (df['d'] <= day-28-28)\n","# 1941-28-28到1941-28 作为测试集\n","valid_mask = (df['d'] > (day-28-28)) & (df['d'] <= (day-28))\n","\n","# 读取商店自己的训练特征\n","MODEL_FEATURES = pd.read_pickle(model_pkl_path +'{}_train_Fea(cb).pkl'.format(store_id)).tolist() \n","\n","categorical_features_indices = ['item_id','dept_id','cat_id','snap_CA','snap_TX','snap_WI',\n","                  'event_name_1','event_type_1','event_name_2','event_type_2',\n","                  'event_name_1_win','event_name_2_win','event_name_1_win_1']\n","categorical_features_indices = set(MODEL_FEATURES) & set(categorical_features_indices) \n","for i in categorical_features_indices:\n","  grid_df[i] = grid_df[i].astype('object')\n","  grid_df[i] = grid_df[i].fillna('no')\n","\n","train_pool = Pool(grid_df[train_mask][MODEL_FEATURES], grid_df[train_mask][TARGET], cat_features = categorical_features_indices) \n","valid_pool = Pool(grid_df[valid_mask][MODEL_FEATURES], grid_df[valid_mask][TARGET], cat_features = categorical_features_indices)\n","\n","# 1914到1941 作为测试集，用训练的模型预测它的\"sales\"，再与真实的\"sales\"计算RMSE\n","test_df = df[df['d']>(day-28)].reset_index(drop=True)\n","\n","# 定义黑盒函数\n","def rf_cv(iterations, l2_leaf_reg, learning_rate, subsample, max_depth, max_bin, min_data_in_leaf):\n","\n","  model = CatBoostRegressor(\n","                  iterations=int(iterations), # 最大树的个数，默认1000，可以设置的大一些，1000~2000\n","                  learning_rate=learning_rate, # 0.01~0.1，范围：[e^{-7}, 1]\n","                  l2_leaf_reg=int(l2_leaf_reg), # 损失函数权重的系数，默认为3，范围：[1,10]\n","                  subsample=subsample, # bagging的采样率，当bootstrap_type为Poisson或Bernoulli时使用，默认0.66\n","                  max_depth=int(max_depth), # 在大多数情况下，最佳深度范围从4到10。建议使用6到10之间的值。\n","                  boosting_type='Plain', # 相当于lgb的GBDT\n","                  one_hot_max_size=2, # 如果feature包含的不同值的数目超过了指定值，将feature转化为float，默认False，范围：[0,25]\n","                  max_bin=int(max_bin), # 同border_count,连续值离散化时bin的最大个数,过大容易过拟合\n","                  objective='RMSE', # 目标函数\n","                  eval_metric='RMSE', # 评估指标\n","                  random_seed=42, # 固定\n","                  nan_mode='Max', # 处理输入数据中缺失值的方法，包括Forbidden(禁止存在缺失)，Min(用最小值补)，Max(用最大值补)，默认Min。\n","                  min_data_in_leaf=int(min_data_in_leaf), # 叶子节点最小样本数，default=1\n","                  boost_from_average= True, # 调整初始的分数为标签的均值，加速模型训练的收敛速度，仅用于回归任务\n","                  verbose=False # 是否显示详细信息，default=1为输出进度条记录\n","                )\n","\n","    cb_model_Bayes = model.fit(train_pool, eval_set = valid_pool) # 训练过程中，绘制，度量值，所用时间等\n","    test_df['preds'] = cb_model_By.predict(test_df[MODEL_FEATURES])\n","    base_score = rmse(test_df['sales'], test_df['preds'])\n","\n","    return -base_score\n","\n","# 给定超参数搜索空间\n","rf_bo = BayesianOptimization(rf_cv, \n","                    {\n","                      'iterations': (1500, 2000),\n","                      'l2_leaf_reg': (3, 10),\n","                      'learning_rate': (0.01, 0.1),\n","                      'subsample': (0.6, 1),\n","                      'max_depth':(6, 10),\n","                      'min_data_in_leaf':(2**10-1,2**15-1),\n","                      'max_bin':(80,150)   \n","                    }\n","                ) \n","opt.maximize(n_iter = 20) # 最大化黑盒函数，迭代100次\n","\n","rf_bo.max # 返回黑盒函数值最大的超参数"],"execution_count":null,"outputs":[{"output_type":"stream","text":["|   iter    |  target   | baggin... | featur... | lambda_l2 | learni... |  max_bin  | min_da... | n_esti... | num_le... | sub_fe... |  sub_row  | subsample | subsam... | tweedi... |\n","-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n","| \u001b[0m 1       \u001b[0m | \u001b[0m-2.005   \u001b[0m | \u001b[0m 0.4722  \u001b[0m | \u001b[0m 0.4987  \u001b[0m | \u001b[0m 0.0196  \u001b[0m | \u001b[0m 0.03115 \u001b[0m | \u001b[0m 87.66   \u001b[0m | \u001b[0m 6.255e+0\u001b[0m | \u001b[0m 1.438e+0\u001b[0m | \u001b[0m 7.805e+0\u001b[0m | \u001b[0m 0.7139  \u001b[0m | \u001b[0m 0.7916  \u001b[0m | \u001b[0m 0.5068  \u001b[0m | \u001b[0m 0.9146  \u001b[0m | \u001b[0m 1.496   \u001b[0m |\n","| \u001b[0m 2       \u001b[0m | \u001b[0m-2.31    \u001b[0m | \u001b[0m 4.875   \u001b[0m | \u001b[0m 0.4995  \u001b[0m | \u001b[0m 0.138   \u001b[0m | \u001b[0m 0.4799  \u001b[0m | \u001b[0m 145.5   \u001b[0m | \u001b[0m 4.86e+03\u001b[0m | \u001b[0m 1.511e+0\u001b[0m | \u001b[0m 1.923e+0\u001b[0m | \u001b[0m 0.7036  \u001b[0m | \u001b[0m 0.8444  \u001b[0m | \u001b[0m 0.776   \u001b[0m | \u001b[0m 1.481   \u001b[0m | \u001b[0m 1.052   \u001b[0m |\n","| \u001b[0m 3       \u001b[0m | \u001b[0m-2.142   \u001b[0m | \u001b[0m 0.554   \u001b[0m | \u001b[0m 0.4238  \u001b[0m | \u001b[0m 0.09402 \u001b[0m | \u001b[0m 0.8591  \u001b[0m | \u001b[0m 118.5   \u001b[0m | \u001b[0m 2.158e+0\u001b[0m | \u001b[0m 1.074e+0\u001b[0m | \u001b[0m 2.461e+0\u001b[0m | \u001b[0m 0.6854  \u001b[0m | \u001b[0m 0.68    \u001b[0m | \u001b[0m 0.5021  \u001b[0m | \u001b[0m 4.48    \u001b[0m | \u001b[0m 1.46    \u001b[0m |\n","| \u001b[0m 4       \u001b[0m | \u001b[0m-2.125   \u001b[0m | \u001b[0m 2.975   \u001b[0m | \u001b[0m 0.5173  \u001b[0m | \u001b[0m 0.1388  \u001b[0m | \u001b[0m 0.1773  \u001b[0m | \u001b[0m 95.7    \u001b[0m | \u001b[0m 3.527e+0\u001b[0m | \u001b[0m 1.179e+0\u001b[0m | \u001b[0m 1.72e+04\u001b[0m | \u001b[0m 0.695   \u001b[0m | \u001b[0m 0.8235  \u001b[0m | \u001b[0m 0.7203  \u001b[0m | \u001b[0m 4.711   \u001b[0m | \u001b[0m 1.236   \u001b[0m |\n","| \u001b[0m 5       \u001b[0m | \u001b[0m-10.6    \u001b[0m | \u001b[0m 4.862   \u001b[0m | \u001b[0m 0.8312  \u001b[0m | \u001b[0m 0.03296 \u001b[0m | \u001b[0m 0.3549  \u001b[0m | \u001b[0m 147.1   \u001b[0m | \u001b[0m 2.911e+0\u001b[0m | \u001b[0m 1.499e+0\u001b[0m | \u001b[0m 3.444e+0\u001b[0m | \u001b[0m 0.9874  \u001b[0m | \u001b[0m 0.7305  \u001b[0m | \u001b[0m 0.6971  \u001b[0m | \u001b[0m 4.234   \u001b[0m | \u001b[0m 1.325   \u001b[0m |\n","| \u001b[0m 6       \u001b[0m | \u001b[0m-2.006   \u001b[0m | \u001b[0m 3.012   \u001b[0m | \u001b[0m 0.6362  \u001b[0m | \u001b[0m 0.09189 \u001b[0m | \u001b[0m 0.01151 \u001b[0m | \u001b[0m 112.2   \u001b[0m | \u001b[0m 3.139e+0\u001b[0m | \u001b[0m 1.102e+0\u001b[0m | \u001b[0m 1.871e+0\u001b[0m | \u001b[0m 0.7395  \u001b[0m | \u001b[0m 0.9646  \u001b[0m | \u001b[0m 0.9989  \u001b[0m | \u001b[0m 1.69    \u001b[0m | \u001b[0m 1.39    \u001b[0m |\n","| \u001b[0m 7       \u001b[0m | \u001b[0m-2.131   \u001b[0m | \u001b[0m 2.602   \u001b[0m | \u001b[0m 0.6728  \u001b[0m | \u001b[0m 0.05175 \u001b[0m | \u001b[0m 0.8602  \u001b[0m | \u001b[0m 100.1   \u001b[0m | \u001b[0m 2.306e+0\u001b[0m | \u001b[0m 1.195e+0\u001b[0m | \u001b[0m 1.877e+0\u001b[0m | \u001b[0m 0.7199  \u001b[0m | \u001b[0m 0.9594  \u001b[0m | \u001b[0m 0.5521  \u001b[0m | \u001b[0m 0.3486  \u001b[0m | \u001b[0m 1.116   \u001b[0m |\n"],"name":"stdout"}]}]}