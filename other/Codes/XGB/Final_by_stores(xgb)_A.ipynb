{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Final_by_stores(xgb)_A.ipynb","provenance":[],"collapsed_sections":["tc4W3-XD6sNM"],"machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"TPU"},"cells":[{"cell_type":"code","metadata":{"id":"z_5SVT6RvYYq","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":127},"executionInfo":{"status":"ok","timestamp":1594951110422,"user_tz":-480,"elapsed":21605,"user":{"displayName":"余凯","photoUrl":"","userId":"13334016005065607071"}},"outputId":"fb32273b-c94b-41a1-baf0-82f5ac0e9d8d"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"jiFkJMb3Ey0F","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1594951114520,"user_tz":-480,"elapsed":2248,"user":{"displayName":"余凯","photoUrl":"","userId":"13334016005065607071"}}},"source":["import numpy as np\n","import pandas as pd\n","import os, sys, gc, time, warnings, pickle, psutil, random\n","import lightgbm as lgb\n","from multiprocessing import Pool        \n","warnings.filterwarnings('ignore')\n","\n","fea_pkl_path = '/content/drive/My Drive/m5-forecasting-accuracy/SilverCode(final)/pkl/fea_pkl/'\n","model_pkl_path = '/content/drive/My Drive/m5-forecasting-accuracy/SilverCode(final)/pkl/model_pkl/'\n","Metric_pkl_path = '/content/drive/My Drive/m5-forecasting-accuracy/SilverCode(final)/pkl/Metric_pkl/'\n","datasets_path = '/content/drive/My Drive/m5-forecasting-accuracy/SilverCode(final)/datasets/'\n","fea_path = '/content/drive/My Drive/m5-forecasting-accuracy/SilverCode(final)/Features/'\n","pred_path = '/content/drive/My Drive/m5-forecasting-accuracy/SilverCode(final)/Predict/'\n","sub_path = '/content/drive/My Drive/m5-forecasting-accuracy/SilverCode(final)/Predict/sub/'\n","\n","\n","BASE = fea_pkl_path + 'grid_part_1.pkl'\n","PRICE = fea_pkl_path + 'grid_part_2.pkl'\n","CALENDAR = fea_pkl_path + 'grid_part_3.pkl'\n","LAGS = fea_pkl_path + 'grid_part_4.pkl'\n","MEAN_ENC = fea_pkl_path + 'grid_part_5.pkl'"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"RhPOT38tOl_q","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1594951116463,"user_tz":-480,"elapsed":2233,"user":{"displayName":"余凯","photoUrl":"","userId":"13334016005065607071"}}},"source":["## 设定随机种子\n","def seed_everything(seed=0):\n","  random.seed(seed)\n","  np.random.seed(seed)\n","\n","## 按照商店读取数据\n","def get_data_by_store(store):\n","    # 读取和连接基本特征\n","    df = pd.concat([pd.read_pickle(BASE), # 9\n","             pd.read_pickle(PRICE).iloc[:,2:], # 11\n","             pd.read_pickle(CALENDAR).iloc[:,2:], # 15 \n","             pd.read_pickle(LAGS).iloc[:,3:], # 37\n","             pd.read_pickle(MEAN_ENC)[mean_features]], # 6  \n","             axis=1) \n","    # df：(47735397, 78)由于行数相同，可以横向拼接\n","    df = df[df['store_id'] == store] # df['store_id'] == store 返回布尔Series，df[df['store_id'] == store] 然后取True的行构成的dataframe\n","    features = [col for col in list(df) if col not in remove_features] # 78 - 7 = 71\n","    df = df[['id', 'd', TARGET] + features] # 71 + 3 = 74 相当于去掉了 'state_id', 'store_id', 'release', 'Holiday'(在CALENDAR里面)\n","    # 选训练开始的天数\n","    df = df[df['d'] >= START_TRAIN].reset_index(drop=True) # drop = True去掉生成的原索引列\n","    return df, features\n","\n","\n","## 读取测试数据\n","def get_base_test():\n","  base_test = pd.DataFrame()\n","\n","  if USE_AUX:\n","    model_path = model_pkl_path\n","  else:\n","    model_path=''\n","\n","  for store_id in STORES_IDS: \n","    temp_df = pd.read_pickle(model_path + 'xgb_test_{}_A.pkl'.format(store_id)) # 不含lag + rolling特征\n","    temp_df['store_id'] = store_id\n","    base_test = pd.concat([base_test, temp_df]).reset_index(drop=True) # 纵向拼接\n","  \n","  return base_test\n","## 制作lag特征\n","def make_lag(LAG_DAY):\n","  lag_df = base_test[['id','d',TARGET]]\n","  col_name = 'sales_lag_' + str(LAG_DAY)\n","  lag_df[col_name] = lag_df.groupby(['id'])[TARGET].transform(lambda x: x.shift(LAG_DAY)).astype(np.float16)\n","  return lag_df[[col_name]]\n","## 递归特征\n","def make_lag_roll(LAG_DAY):\n","  shift_day = LAG_DAY[0]\n","  roll_wind = LAG_DAY[1]\n","  lag_df = base_test[['id','d',TARGET]] \n","  col_name = 'rolling_mean_tmp_'+str(shift_day)+'_'+str(roll_wind)\n","  lag_df[col_name] = lag_df.groupby(['id'])[TARGET].transform(lambda x: x.shift(shift_day).rolling(roll_wind).mean()) \n","\n","  return lag_df[[col_name]]\n","## 多线程执行，用于测试集融合\n","def df_parallelize_run(func, t_split):\n","  num_cores = np.min([N_CORES,len(t_split)])\n","  pool = Pool(num_cores)\n","  df = pd.concat(pool.map(func, t_split), axis=1)\n","  pool.close()\n","  pool.join()\n","  return df\n","\n","# lag + rolling\n","SHIFT_DAY = 28\n","N_LAGS = 15\n","LAGS_SPLIT = [col for col in range(SHIFT_DAY, SHIFT_DAY + N_LAGS)]\n","ROLS_SPLIT = []\n","for i in [1,7,14]:\n","  for j in [7,14,30,60]:\n","    ROLS_SPLIT.append([i,j])\n","\n","# grid_df = pd.concat([grid_df, df_parallelize_run(make_lag_roll, ROLS_SPLIT)], axis=1)\n","\n","\n","VER = 1 # 设置模型的版本\n","SEED = 42 \n","seed_everything(SEED) # 消除随机性\n","N_CORES = psutil.cpu_count() # 可使用的CPU内核\n","\n","TARGET = 'sales' # Label\n","# START_TRAIN = 1600 # 快速训练，验证是否有BUG\n","START_TRAIN = 0 # 真正训练\n","END_TRAIN = 1913\n","P_HORIZON = 28 # 预测范围\n","USE_AUX = True # 使用预训练好的模型\n","\n","remove_features = ['id', 'state_id', 'store_id', 'release', 'Holiday', 'd', TARGET]          \n","mean_features = ['enc_cat_id_mean', 'enc_cat_id_std', 'enc_dept_id_mean', 'enc_dept_id_std', 'enc_item_id_mean', 'enc_item_id_std'] \n","# 按商店分别训练，每个商店可以只能按类别、部门、商品的销量聚合取mean\\std，故只选这6个特征\n","STORES_IDS = ['CA_1','CA_2','CA_3','CA_4','TX_1','TX_2','TX_3','WI_1','WI_2','WI_3']"],"execution_count":3,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"N_R3Odek2Vl1","colab_type":"text"},"source":["## 每个商店的xgb参数及类别特征处理"]},{"cell_type":"code","metadata":{"id":"TbHapyQzzrcE","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1594951119929,"user_tz":-480,"elapsed":932,"user":{"displayName":"余凯","photoUrl":"","userId":"13334016005065607071"}}},"source":["xgb_params_common = {\n","            'booster': 'gbtree',\n","            'objective': 'reg:tweedie',\n","            'eval_metric': 'rmse',\n","            'min_data_in_leaf': 11801,\n","            'lambda': 0.021982796763644744, \n","            'eta': 0.04723157294394453,\n","            'colsample_bytree': 0.9329928507911868, \n","            'subsample': 0.5951931300022044,    \n","            'max_bin':67,\n","            'num_leaves': 25631,\n","            'sub_row': 0.6184421797679618,\n","            'subsample_freq': 3,\n","            'silent':1, \n","            'seed': 42,\n","            'tree_method': 'hist',\n","            'tweedie_variance_power':1.1833186379351004,\n","            'boost_from_average': False\n","           }"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"RyUc8phrWmGF","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1594951124062,"user_tz":-480,"elapsed":2476,"user":{"displayName":"余凯","photoUrl":"","userId":"13334016005065607071"}},"outputId":"ddd1260c-e274-44c0-d969-060a53ddb79f"},"source":["# 下面处理类别特征需要用到的工具包\n","import xgboost as xgb\n","from sklearn.decomposition import PCA\n","from sklearn import preprocessing\n","from keras.layers.embeddings import Embedding\n","from keras.models import Sequential\n","import tensorflow as tf\n","import random as rn\n","import os\n","os.environ['PYTHONHASHSEED'] = '0'\n","np.random.seed(42)\n","rn.seed(12345)\n","session_conf = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)"],"execution_count":5,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"52JVXYxX2heR","colab_type":"text"},"source":["## 每个商店单独训练模型"]},{"cell_type":"code","metadata":{"id":"C84oJ59GPJ25","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1594957765871,"user_tz":-480,"elapsed":6600538,"user":{"displayName":"余凯","photoUrl":"","userId":"13334016005065607071"}},"outputId":"816ddf6b-0b48-4d97-9116-6140040c4ecf"},"source":["############################################# Train Models ###############################################\n","for store_id in STORES_IDS: # 每个商店单独训练\n","    print('Train', store_id)\n","    grid_df, features_columns = get_data_by_store(store_id) \n","    calendar_win = pd.read_csv(fea_path + 'CA1_TX2_TX3_holidays.csv')\n","    calendar_win['d'] = calendar_win['d'].apply(lambda x: x.split('_',2)[1]).astype(np.int16) \n","    calendar_win['event_name_1_win'] = calendar_win['event_name_1_win'].astype('category') \n","    grid_df = grid_df.merge(calendar_win, on='d', how='left') \n","\n","    #################################### PCA ####################################\n","    pca_fea = ['snap_CA', 'snap_TX', 'snap_WI'] # 这三个分别onehot编码之后，再PCA，能保持100%的信息\n","    pca_df = pd.DataFrame()\n","    pca = PCA(n_components = 'mle')\n","    OneHot_snap = pd.get_dummies(grid_df[pca_fea])\n","    pca_df = pd.concat([pd.DataFrame(pca.fit_transform(OneHot_snap.iloc[:,0:2]), columns = ['snap_CA_pca']),\n","               pd.DataFrame(pca.fit_transform(OneHot_snap.iloc[:,2:4]), columns = ['snap_TX_pca']),\n","               pd.DataFrame(pca.fit_transform(OneHot_snap.iloc[:,4:6]), columns = ['snap_WI_pca'])], axis=1)\n","    #################################### One-Hot ####################################\n","    one_hot_fea = ['cat_id', 'event_type_2'] # 'cat_id'特征值个数为3，'event_type_2'：2\n","    one_hot_df = pd.get_dummies(grid_df[one_hot_fea]) \n","    ############################ LabelEncoder + Enbedding ##########################\n","    ## 先用label编码\n","    embedding_fea = ['dept_id', 'event_name_1', 'event_type_1', 'event_name_2', 'event_name_1_win']\n","    for i in embedding_fea:\n","      if grid_df[i].dtypes=='category':\n","        le = preprocessing.LabelEncoder()\n","        grid_df[i] = le.fit_transform(list(grid_df[i].values))\n","\n","    intput_vec = [7,31,5,5,32]\n","    output_vec = [3,10,3,3,10]\n","    embedding_df = pd.DataFrame()\n","    int_j = 0\n","    out_k = 0\n","\n","    for i in embedding_fea:\n","      model = Sequential()\n","      model.add(Embedding(intput_vec[int_j], output_vec[out_k], input_length = 1))\n","      model.compile(loss='mean_squared_error', optimizer='rmsprop')\n","      input_array = grid_df[[i]].values\n","      output_array = model.predict(input_array).reshape((-1, output_vec[out_k]))\n","      # intput_vec[int_j]：不同特征值的个数(词汇表大小) output_vec[out_k]：词向量的维度\n","      # 输入尺寸为 (batch_size, sequence_length) 的 2D 张量\n","      # 输出尺寸为 (batch_size, sequence_length, output_dim) 的 3D 张量，比如：'dept_id' embedding之后(4873639, 1, 3)，需要reshape一下。\n","      temp_df = pd.DataFrame(output_array)\n","      embedding_df = pd.concat([embedding_df, temp_df], axis = 1)\n","      int_j += 1\n","      out_k += 1\n","\n","    embedding_df.columns = [f'eme_{col}' for col in range(len(embedding_df.columns))]\n","\n","    category_feature = ['item_id', 'dept_id', 'cat_id', 'snap_CA', 'snap_TX', 'snap_WI',\n","               'event_name_1', 'event_type_1', 'event_name_2', 'event_type_2', 'event_name_1_win'] \n","                # 由于item_id有3049个特征值，没办法处理，剔除掉，其他的分开处理\n","    grid_df.drop(columns = category_feature, inplace = True) ## BUG：不能剔除掉 \"id\" 否则后面没办法迭代按照 id 生成迭代预测的特征了。\n","    ## 融合到一起\n","    xgb_df = pd.concat([embedding_df, one_hot_df, pca_df], axis=1)\n","    grid_df = pd.concat([grid_df, xgb_df], axis = 1)\n","    features_columns = list(set(features_columns).difference(set(category_feature))) + xgb_df.columns.to_list()\n","    # set(listA).difference(set(listB)) 去掉AB的交集，取A剩下的。set运算完之后，返回的还是set，需要转化为list\n","    print(features_columns)\n","    del xgb_df, embedding_df, one_hot_df, pca_df\n","    print('finish：{}'.format(store_id))\n","\n","    xgb_params = xgb_params_common\n","\n","    train_mask = grid_df['d'] <= END_TRAIN - P_HORIZON # 1<= train <=1941-28 \n","    valid_mask = (grid_df['d'] > (END_TRAIN - P_HORIZON)) & (grid_df['d'] <= END_TRAIN) # 1941-28< valid <=1941\n","    preds_mask = grid_df['d'] > (END_TRAIN - 100) \n","\n","    train_data = xgb.DMatrix(grid_df[train_mask][features_columns], label = grid_df[train_mask][TARGET])\n","    valid_data = xgb.DMatrix(grid_df[valid_mask][features_columns], label = grid_df[valid_mask][TARGET])\n","\n","    # 构造一个后面预测用的数据集 \n","    grid_df = grid_df[preds_mask].reset_index(drop=True)\n","    keep_cols = [col for col in list(grid_df) if '_tmp_' not in col] # '_tmp_' 滞后 + rolling 比如：rolling_mean_tmp_14_60 去掉了12列\n","    grid_df = grid_df[keep_cols] # CA1：75 - 12 = 63 (390272, 63)  [1842, 1969] 128天\n","    grid_df.to_pickle(model_pkl_path + 'xgb_test_{}_A.pkl'.format(store_id))\n","    \n","    # 训练模型\n","    seed_everything(SEED)\n","    watchlist = [(valid_data, 'eval')]\n","    estimator = xgb.train(xgb_params, train_data, evals = watchlist, num_boost_round = 20000, verbose_eval = 100, early_stopping_rounds = 100)\n","    # early_stopping_rounds 验证集的误差迭代到一定程度在100次内不能再继续降低，就停止迭代。要求evals里至少有一个元素。\n","    # 存储模型为二进制文件，下次读取的时候，速度更快\n","    model_name = model_pkl_path + 'xgb_model_{}_v{}_A.bin'.format(store_id, str(VER))\n","    pickle.dump(estimator, open(model_name, 'wb'))\n","\n","    del grid_df, train_data, valid_data, estimator\n","    gc.collect()\n","\n","## 遇到的问题：训练的时候只迭代几步就结束了\n","# Train CA_1\n","# finish：CA_1\n","# [0]\ttrain-rmse:4.58096\teval-rmse:3.72794\n","# [9]\ttrain-rmse:4.2113\teval-rmse:3.37202\n","# Train CA_2\n","## 解决办法：在train中设置：num_boost_round，因为没有设置迭代次数的话，默认只迭代10次就停止了。 \n","## Xgboost中的迭代次数 num_boost_round 和LightGBM中的迭代次数 n_estimators 是一样的"],"execution_count":7,"outputs":[{"output_type":"stream","text":["Train CA_1\n","['rolling_mean_60', 'rolling_std_14', 'sales_lag_35', 'enc_dept_id_std', 'rolling_mean_tmp_7_30', 'enc_cat_id_mean', 'sales_lag_30', 'sales_lag_34', 'sales_lag_39', 'enc_item_id_mean', 'tm_wm', 'price_norm', 'rolling_mean_tmp_14_30', 'sales_lag_41', 'rolling_mean_tmp_7_14', 'sales_lag_38', 'price_std', 'sell_price', 'tm_d', 'sales_lag_31', 'price_momentum_y', 'price_max', 'sales_lag_32', 'rolling_mean_tmp_7_7', 'rolling_mean_tmp_1_14', 'price_momentum', 'rolling_mean_tmp_1_60', 'rolling_mean_tmp_14_60', 'sales_lag_42', 'tm_y', 'sales_lag_29', 'rolling_mean_tmp_14_7', 'enc_cat_id_std', 'sales_lag_36', 'price_mean', 'sales_lag_37', 'sales_lag_28', 'rolling_std_180', 'enc_item_id_std', 'rolling_mean_14', 'tm_m', 'rolling_mean_tmp_14_14', 'rolling_mean_tmp_1_30', 'price_min', 'sales_lag_33', 'tm_w_end', 'rolling_mean_7', 'item_nunique', 'price_momentum_m', 'tm_w', 'enc_dept_id_mean', 'price_nunique', 'rolling_mean_30', 'rolling_mean_180', 'rolling_mean_tmp_1_7', 'sales_lag_40', 'tm_dw', 'rolling_std_60', 'rolling_std_7', 'rolling_mean_tmp_7_60', 'rolling_std_30', 'eme_0', 'eme_1', 'eme_2', 'eme_3', 'eme_4', 'eme_5', 'eme_6', 'eme_7', 'eme_8', 'eme_9', 'eme_10', 'eme_11', 'eme_12', 'eme_13', 'eme_14', 'eme_15', 'eme_16', 'eme_17', 'eme_18', 'eme_19', 'eme_20', 'eme_21', 'eme_22', 'eme_23', 'eme_24', 'eme_25', 'eme_26', 'eme_27', 'eme_28', 'cat_id_FOODS', 'cat_id_HOBBIES', 'cat_id_HOUSEHOLD', 'event_type_2_Cultural', 'event_type_2_Religious', 'snap_CA_pca', 'snap_TX_pca', 'snap_WI_pca']\n","finish：CA_1\n","[0]\teval-rmse:3.58891\n","Will train until eval-rmse hasn't improved in 100 rounds.\n","[100]\teval-rmse:2.03738\n","[200]\teval-rmse:2.03398\n","[300]\teval-rmse:2.02942\n","[400]\teval-rmse:2.02447\n","[500]\teval-rmse:2.0213\n","[600]\teval-rmse:2.02065\n","[700]\teval-rmse:2.01948\n","[800]\teval-rmse:2.01727\n","[900]\teval-rmse:2.01662\n","[1000]\teval-rmse:2.01741\n","Stopping. Best iteration:\n","[945]\teval-rmse:2.016\n","\n","Train CA_2\n","['rolling_mean_60', 'rolling_std_14', 'sales_lag_35', 'enc_dept_id_std', 'rolling_mean_tmp_7_30', 'enc_cat_id_mean', 'sales_lag_30', 'sales_lag_34', 'sales_lag_39', 'enc_item_id_mean', 'tm_wm', 'price_norm', 'rolling_mean_tmp_14_30', 'sales_lag_41', 'rolling_mean_tmp_7_14', 'sales_lag_38', 'price_std', 'sell_price', 'tm_d', 'sales_lag_31', 'price_momentum_y', 'price_max', 'sales_lag_32', 'rolling_mean_tmp_7_7', 'rolling_mean_tmp_1_14', 'price_momentum', 'rolling_mean_tmp_1_60', 'rolling_mean_tmp_14_60', 'sales_lag_42', 'tm_y', 'sales_lag_29', 'rolling_mean_tmp_14_7', 'enc_cat_id_std', 'sales_lag_36', 'price_mean', 'sales_lag_37', 'sales_lag_28', 'rolling_std_180', 'enc_item_id_std', 'rolling_mean_14', 'tm_m', 'rolling_mean_tmp_14_14', 'rolling_mean_tmp_1_30', 'price_min', 'sales_lag_33', 'tm_w_end', 'rolling_mean_7', 'item_nunique', 'price_momentum_m', 'tm_w', 'enc_dept_id_mean', 'price_nunique', 'rolling_mean_30', 'rolling_mean_180', 'rolling_mean_tmp_1_7', 'sales_lag_40', 'tm_dw', 'rolling_std_60', 'rolling_std_7', 'rolling_mean_tmp_7_60', 'rolling_std_30', 'eme_0', 'eme_1', 'eme_2', 'eme_3', 'eme_4', 'eme_5', 'eme_6', 'eme_7', 'eme_8', 'eme_9', 'eme_10', 'eme_11', 'eme_12', 'eme_13', 'eme_14', 'eme_15', 'eme_16', 'eme_17', 'eme_18', 'eme_19', 'eme_20', 'eme_21', 'eme_22', 'eme_23', 'eme_24', 'eme_25', 'eme_26', 'eme_27', 'eme_28', 'cat_id_FOODS', 'cat_id_HOBBIES', 'cat_id_HOUSEHOLD', 'event_type_2_Cultural', 'event_type_2_Religious', 'snap_CA_pca', 'snap_TX_pca', 'snap_WI_pca']\n","finish：CA_2\n","[0]\teval-rmse:3.20553\n","Will train until eval-rmse hasn't improved in 100 rounds.\n","[100]\teval-rmse:1.90272\n","[200]\teval-rmse:1.89537\n","[300]\teval-rmse:1.89392\n","[400]\teval-rmse:1.89013\n","[500]\teval-rmse:1.88817\n","Stopping. Best iteration:\n","[466]\teval-rmse:1.88651\n","\n","Train CA_3\n","['rolling_mean_60', 'rolling_std_14', 'sales_lag_35', 'enc_dept_id_std', 'rolling_mean_tmp_7_30', 'enc_cat_id_mean', 'sales_lag_30', 'sales_lag_34', 'sales_lag_39', 'enc_item_id_mean', 'tm_wm', 'price_norm', 'rolling_mean_tmp_14_30', 'sales_lag_41', 'rolling_mean_tmp_7_14', 'sales_lag_38', 'price_std', 'sell_price', 'tm_d', 'sales_lag_31', 'price_momentum_y', 'price_max', 'sales_lag_32', 'rolling_mean_tmp_7_7', 'rolling_mean_tmp_1_14', 'price_momentum', 'rolling_mean_tmp_1_60', 'rolling_mean_tmp_14_60', 'sales_lag_42', 'tm_y', 'sales_lag_29', 'rolling_mean_tmp_14_7', 'enc_cat_id_std', 'sales_lag_36', 'price_mean', 'sales_lag_37', 'sales_lag_28', 'rolling_std_180', 'enc_item_id_std', 'rolling_mean_14', 'tm_m', 'rolling_mean_tmp_14_14', 'rolling_mean_tmp_1_30', 'price_min', 'sales_lag_33', 'tm_w_end', 'rolling_mean_7', 'item_nunique', 'price_momentum_m', 'tm_w', 'enc_dept_id_mean', 'price_nunique', 'rolling_mean_30', 'rolling_mean_180', 'rolling_mean_tmp_1_7', 'sales_lag_40', 'tm_dw', 'rolling_std_60', 'rolling_std_7', 'rolling_mean_tmp_7_60', 'rolling_std_30', 'eme_0', 'eme_1', 'eme_2', 'eme_3', 'eme_4', 'eme_5', 'eme_6', 'eme_7', 'eme_8', 'eme_9', 'eme_10', 'eme_11', 'eme_12', 'eme_13', 'eme_14', 'eme_15', 'eme_16', 'eme_17', 'eme_18', 'eme_19', 'eme_20', 'eme_21', 'eme_22', 'eme_23', 'eme_24', 'eme_25', 'eme_26', 'eme_27', 'eme_28', 'cat_id_FOODS', 'cat_id_HOBBIES', 'cat_id_HOUSEHOLD', 'event_type_2_Cultural', 'event_type_2_Religious', 'snap_CA_pca', 'snap_TX_pca', 'snap_WI_pca']\n","finish：CA_3\n","[0]\teval-rmse:5.23227\n","Will train until eval-rmse hasn't improved in 100 rounds.\n","[100]\teval-rmse:2.54648\n","Stopping. Best iteration:\n","[74]\teval-rmse:2.54205\n","\n","Train CA_4\n","['rolling_mean_60', 'rolling_std_14', 'sales_lag_35', 'enc_dept_id_std', 'rolling_mean_tmp_7_30', 'enc_cat_id_mean', 'sales_lag_30', 'sales_lag_34', 'sales_lag_39', 'enc_item_id_mean', 'tm_wm', 'price_norm', 'rolling_mean_tmp_14_30', 'sales_lag_41', 'rolling_mean_tmp_7_14', 'sales_lag_38', 'price_std', 'sell_price', 'tm_d', 'sales_lag_31', 'price_momentum_y', 'price_max', 'sales_lag_32', 'rolling_mean_tmp_7_7', 'rolling_mean_tmp_1_14', 'price_momentum', 'rolling_mean_tmp_1_60', 'rolling_mean_tmp_14_60', 'sales_lag_42', 'tm_y', 'sales_lag_29', 'rolling_mean_tmp_14_7', 'enc_cat_id_std', 'sales_lag_36', 'price_mean', 'sales_lag_37', 'sales_lag_28', 'rolling_std_180', 'enc_item_id_std', 'rolling_mean_14', 'tm_m', 'rolling_mean_tmp_14_14', 'rolling_mean_tmp_1_30', 'price_min', 'sales_lag_33', 'tm_w_end', 'rolling_mean_7', 'item_nunique', 'price_momentum_m', 'tm_w', 'enc_dept_id_mean', 'price_nunique', 'rolling_mean_30', 'rolling_mean_180', 'rolling_mean_tmp_1_7', 'sales_lag_40', 'tm_dw', 'rolling_std_60', 'rolling_std_7', 'rolling_mean_tmp_7_60', 'rolling_std_30', 'eme_0', 'eme_1', 'eme_2', 'eme_3', 'eme_4', 'eme_5', 'eme_6', 'eme_7', 'eme_8', 'eme_9', 'eme_10', 'eme_11', 'eme_12', 'eme_13', 'eme_14', 'eme_15', 'eme_16', 'eme_17', 'eme_18', 'eme_19', 'eme_20', 'eme_21', 'eme_22', 'eme_23', 'eme_24', 'eme_25', 'eme_26', 'eme_27', 'eme_28', 'cat_id_FOODS', 'cat_id_HOBBIES', 'cat_id_HOUSEHOLD', 'event_type_2_Cultural', 'event_type_2_Religious', 'snap_CA_pca', 'snap_TX_pca', 'snap_WI_pca']\n","finish：CA_4\n","[0]\teval-rmse:1.90212\n","Will train until eval-rmse hasn't improved in 100 rounds.\n","[100]\teval-rmse:1.3368\n","[200]\teval-rmse:1.33561\n","[300]\teval-rmse:1.33441\n","[400]\teval-rmse:1.33384\n","[500]\teval-rmse:1.33418\n","Stopping. Best iteration:\n","[422]\teval-rmse:1.33368\n","\n","Train TX_1\n","['rolling_mean_60', 'rolling_std_14', 'sales_lag_35', 'enc_dept_id_std', 'rolling_mean_tmp_7_30', 'enc_cat_id_mean', 'sales_lag_30', 'sales_lag_34', 'sales_lag_39', 'enc_item_id_mean', 'tm_wm', 'price_norm', 'rolling_mean_tmp_14_30', 'sales_lag_41', 'rolling_mean_tmp_7_14', 'sales_lag_38', 'price_std', 'sell_price', 'tm_d', 'sales_lag_31', 'price_momentum_y', 'price_max', 'sales_lag_32', 'rolling_mean_tmp_7_7', 'rolling_mean_tmp_1_14', 'price_momentum', 'rolling_mean_tmp_1_60', 'rolling_mean_tmp_14_60', 'sales_lag_42', 'tm_y', 'sales_lag_29', 'rolling_mean_tmp_14_7', 'enc_cat_id_std', 'sales_lag_36', 'price_mean', 'sales_lag_37', 'sales_lag_28', 'rolling_std_180', 'enc_item_id_std', 'rolling_mean_14', 'tm_m', 'rolling_mean_tmp_14_14', 'rolling_mean_tmp_1_30', 'price_min', 'sales_lag_33', 'tm_w_end', 'rolling_mean_7', 'item_nunique', 'price_momentum_m', 'tm_w', 'enc_dept_id_mean', 'price_nunique', 'rolling_mean_30', 'rolling_mean_180', 'rolling_mean_tmp_1_7', 'sales_lag_40', 'tm_dw', 'rolling_std_60', 'rolling_std_7', 'rolling_mean_tmp_7_60', 'rolling_std_30', 'eme_0', 'eme_1', 'eme_2', 'eme_3', 'eme_4', 'eme_5', 'eme_6', 'eme_7', 'eme_8', 'eme_9', 'eme_10', 'eme_11', 'eme_12', 'eme_13', 'eme_14', 'eme_15', 'eme_16', 'eme_17', 'eme_18', 'eme_19', 'eme_20', 'eme_21', 'eme_22', 'eme_23', 'eme_24', 'eme_25', 'eme_26', 'eme_27', 'eme_28', 'cat_id_FOODS', 'cat_id_HOBBIES', 'cat_id_HOUSEHOLD', 'event_type_2_Cultural', 'event_type_2_Religious', 'snap_CA_pca', 'snap_TX_pca', 'snap_WI_pca']\n","finish：TX_1\n","[0]\teval-rmse:3.10179\n","Will train until eval-rmse hasn't improved in 100 rounds.\n","[100]\teval-rmse:1.64187\n","[200]\teval-rmse:1.6372\n","[300]\teval-rmse:1.63399\n","[400]\teval-rmse:1.6333\n","[500]\teval-rmse:1.63217\n","[600]\teval-rmse:1.6324\n","Stopping. Best iteration:\n","[538]\teval-rmse:1.6315\n","\n","Train TX_2\n","['rolling_mean_60', 'rolling_std_14', 'sales_lag_35', 'enc_dept_id_std', 'rolling_mean_tmp_7_30', 'enc_cat_id_mean', 'sales_lag_30', 'sales_lag_34', 'sales_lag_39', 'enc_item_id_mean', 'tm_wm', 'price_norm', 'rolling_mean_tmp_14_30', 'sales_lag_41', 'rolling_mean_tmp_7_14', 'sales_lag_38', 'price_std', 'sell_price', 'tm_d', 'sales_lag_31', 'price_momentum_y', 'price_max', 'sales_lag_32', 'rolling_mean_tmp_7_7', 'rolling_mean_tmp_1_14', 'price_momentum', 'rolling_mean_tmp_1_60', 'rolling_mean_tmp_14_60', 'sales_lag_42', 'tm_y', 'sales_lag_29', 'rolling_mean_tmp_14_7', 'enc_cat_id_std', 'sales_lag_36', 'price_mean', 'sales_lag_37', 'sales_lag_28', 'rolling_std_180', 'enc_item_id_std', 'rolling_mean_14', 'tm_m', 'rolling_mean_tmp_14_14', 'rolling_mean_tmp_1_30', 'price_min', 'sales_lag_33', 'tm_w_end', 'rolling_mean_7', 'item_nunique', 'price_momentum_m', 'tm_w', 'enc_dept_id_mean', 'price_nunique', 'rolling_mean_30', 'rolling_mean_180', 'rolling_mean_tmp_1_7', 'sales_lag_40', 'tm_dw', 'rolling_std_60', 'rolling_std_7', 'rolling_mean_tmp_7_60', 'rolling_std_30', 'eme_0', 'eme_1', 'eme_2', 'eme_3', 'eme_4', 'eme_5', 'eme_6', 'eme_7', 'eme_8', 'eme_9', 'eme_10', 'eme_11', 'eme_12', 'eme_13', 'eme_14', 'eme_15', 'eme_16', 'eme_17', 'eme_18', 'eme_19', 'eme_20', 'eme_21', 'eme_22', 'eme_23', 'eme_24', 'eme_25', 'eme_26', 'eme_27', 'eme_28', 'cat_id_FOODS', 'cat_id_HOBBIES', 'cat_id_HOUSEHOLD', 'event_type_2_Cultural', 'event_type_2_Religious', 'snap_CA_pca', 'snap_TX_pca', 'snap_WI_pca']\n","finish：TX_2\n","[0]\teval-rmse:3.61158\n","Will train until eval-rmse hasn't improved in 100 rounds.\n","[100]\teval-rmse:1.74327\n","Stopping. Best iteration:\n","[61]\teval-rmse:1.72126\n","\n","Train TX_3\n","['rolling_mean_60', 'rolling_std_14', 'sales_lag_35', 'enc_dept_id_std', 'rolling_mean_tmp_7_30', 'enc_cat_id_mean', 'sales_lag_30', 'sales_lag_34', 'sales_lag_39', 'enc_item_id_mean', 'tm_wm', 'price_norm', 'rolling_mean_tmp_14_30', 'sales_lag_41', 'rolling_mean_tmp_7_14', 'sales_lag_38', 'price_std', 'sell_price', 'tm_d', 'sales_lag_31', 'price_momentum_y', 'price_max', 'sales_lag_32', 'rolling_mean_tmp_7_7', 'rolling_mean_tmp_1_14', 'price_momentum', 'rolling_mean_tmp_1_60', 'rolling_mean_tmp_14_60', 'sales_lag_42', 'tm_y', 'sales_lag_29', 'rolling_mean_tmp_14_7', 'enc_cat_id_std', 'sales_lag_36', 'price_mean', 'sales_lag_37', 'sales_lag_28', 'rolling_std_180', 'enc_item_id_std', 'rolling_mean_14', 'tm_m', 'rolling_mean_tmp_14_14', 'rolling_mean_tmp_1_30', 'price_min', 'sales_lag_33', 'tm_w_end', 'rolling_mean_7', 'item_nunique', 'price_momentum_m', 'tm_w', 'enc_dept_id_mean', 'price_nunique', 'rolling_mean_30', 'rolling_mean_180', 'rolling_mean_tmp_1_7', 'sales_lag_40', 'tm_dw', 'rolling_std_60', 'rolling_std_7', 'rolling_mean_tmp_7_60', 'rolling_std_30', 'eme_0', 'eme_1', 'eme_2', 'eme_3', 'eme_4', 'eme_5', 'eme_6', 'eme_7', 'eme_8', 'eme_9', 'eme_10', 'eme_11', 'eme_12', 'eme_13', 'eme_14', 'eme_15', 'eme_16', 'eme_17', 'eme_18', 'eme_19', 'eme_20', 'eme_21', 'eme_22', 'eme_23', 'eme_24', 'eme_25', 'eme_26', 'eme_27', 'eme_28', 'cat_id_FOODS', 'cat_id_HOBBIES', 'cat_id_HOUSEHOLD', 'event_type_2_Cultural', 'event_type_2_Religious', 'snap_CA_pca', 'snap_TX_pca', 'snap_WI_pca']\n","finish：TX_3\n","[0]\teval-rmse:3.35682\n","Will train until eval-rmse hasn't improved in 100 rounds.\n","[100]\teval-rmse:1.69494\n","Stopping. Best iteration:\n","[74]\teval-rmse:1.68902\n","\n","Train WI_1\n","['rolling_mean_60', 'rolling_std_14', 'sales_lag_35', 'enc_dept_id_std', 'rolling_mean_tmp_7_30', 'enc_cat_id_mean', 'sales_lag_30', 'sales_lag_34', 'sales_lag_39', 'enc_item_id_mean', 'tm_wm', 'price_norm', 'rolling_mean_tmp_14_30', 'sales_lag_41', 'rolling_mean_tmp_7_14', 'sales_lag_38', 'price_std', 'sell_price', 'tm_d', 'sales_lag_31', 'price_momentum_y', 'price_max', 'sales_lag_32', 'rolling_mean_tmp_7_7', 'rolling_mean_tmp_1_14', 'price_momentum', 'rolling_mean_tmp_1_60', 'rolling_mean_tmp_14_60', 'sales_lag_42', 'tm_y', 'sales_lag_29', 'rolling_mean_tmp_14_7', 'enc_cat_id_std', 'sales_lag_36', 'price_mean', 'sales_lag_37', 'sales_lag_28', 'rolling_std_180', 'enc_item_id_std', 'rolling_mean_14', 'tm_m', 'rolling_mean_tmp_14_14', 'rolling_mean_tmp_1_30', 'price_min', 'sales_lag_33', 'tm_w_end', 'rolling_mean_7', 'item_nunique', 'price_momentum_m', 'tm_w', 'enc_dept_id_mean', 'price_nunique', 'rolling_mean_30', 'rolling_mean_180', 'rolling_mean_tmp_1_7', 'sales_lag_40', 'tm_dw', 'rolling_std_60', 'rolling_std_7', 'rolling_mean_tmp_7_60', 'rolling_std_30', 'eme_0', 'eme_1', 'eme_2', 'eme_3', 'eme_4', 'eme_5', 'eme_6', 'eme_7', 'eme_8', 'eme_9', 'eme_10', 'eme_11', 'eme_12', 'eme_13', 'eme_14', 'eme_15', 'eme_16', 'eme_17', 'eme_18', 'eme_19', 'eme_20', 'eme_21', 'eme_22', 'eme_23', 'eme_24', 'eme_25', 'eme_26', 'eme_27', 'eme_28', 'cat_id_FOODS', 'cat_id_HOBBIES', 'cat_id_HOUSEHOLD', 'event_type_2_Cultural', 'event_type_2_Religious', 'snap_CA_pca', 'snap_TX_pca', 'snap_WI_pca']\n","finish：WI_1\n","[0]\teval-rmse:2.61445\n","Will train until eval-rmse hasn't improved in 100 rounds.\n","[100]\teval-rmse:1.59925\n","[200]\teval-rmse:1.59581\n","[300]\teval-rmse:1.5953\n","Stopping. Best iteration:\n","[288]\teval-rmse:1.5951\n","\n","Train WI_2\n","['rolling_mean_60', 'rolling_std_14', 'sales_lag_35', 'enc_dept_id_std', 'rolling_mean_tmp_7_30', 'enc_cat_id_mean', 'sales_lag_30', 'sales_lag_34', 'sales_lag_39', 'enc_item_id_mean', 'tm_wm', 'price_norm', 'rolling_mean_tmp_14_30', 'sales_lag_41', 'rolling_mean_tmp_7_14', 'sales_lag_38', 'price_std', 'sell_price', 'tm_d', 'sales_lag_31', 'price_momentum_y', 'price_max', 'sales_lag_32', 'rolling_mean_tmp_7_7', 'rolling_mean_tmp_1_14', 'price_momentum', 'rolling_mean_tmp_1_60', 'rolling_mean_tmp_14_60', 'sales_lag_42', 'tm_y', 'sales_lag_29', 'rolling_mean_tmp_14_7', 'enc_cat_id_std', 'sales_lag_36', 'price_mean', 'sales_lag_37', 'sales_lag_28', 'rolling_std_180', 'enc_item_id_std', 'rolling_mean_14', 'tm_m', 'rolling_mean_tmp_14_14', 'rolling_mean_tmp_1_30', 'price_min', 'sales_lag_33', 'tm_w_end', 'rolling_mean_7', 'item_nunique', 'price_momentum_m', 'tm_w', 'enc_dept_id_mean', 'price_nunique', 'rolling_mean_30', 'rolling_mean_180', 'rolling_mean_tmp_1_7', 'sales_lag_40', 'tm_dw', 'rolling_std_60', 'rolling_std_7', 'rolling_mean_tmp_7_60', 'rolling_std_30', 'eme_0', 'eme_1', 'eme_2', 'eme_3', 'eme_4', 'eme_5', 'eme_6', 'eme_7', 'eme_8', 'eme_9', 'eme_10', 'eme_11', 'eme_12', 'eme_13', 'eme_14', 'eme_15', 'eme_16', 'eme_17', 'eme_18', 'eme_19', 'eme_20', 'eme_21', 'eme_22', 'eme_23', 'eme_24', 'eme_25', 'eme_26', 'eme_27', 'eme_28', 'cat_id_FOODS', 'cat_id_HOBBIES', 'cat_id_HOUSEHOLD', 'event_type_2_Cultural', 'event_type_2_Religious', 'snap_CA_pca', 'snap_TX_pca', 'snap_WI_pca']\n","finish：WI_2\n","[0]\teval-rmse:5.02285\n","Will train until eval-rmse hasn't improved in 100 rounds.\n","[100]\teval-rmse:2.7049\n","[200]\teval-rmse:2.66841\n","[300]\teval-rmse:2.6618\n","[400]\teval-rmse:2.66256\n","Stopping. Best iteration:\n","[316]\teval-rmse:2.6584\n","\n","Train WI_3\n","['rolling_mean_60', 'rolling_std_14', 'sales_lag_35', 'enc_dept_id_std', 'rolling_mean_tmp_7_30', 'enc_cat_id_mean', 'sales_lag_30', 'sales_lag_34', 'sales_lag_39', 'enc_item_id_mean', 'tm_wm', 'price_norm', 'rolling_mean_tmp_14_30', 'sales_lag_41', 'rolling_mean_tmp_7_14', 'sales_lag_38', 'price_std', 'sell_price', 'tm_d', 'sales_lag_31', 'price_momentum_y', 'price_max', 'sales_lag_32', 'rolling_mean_tmp_7_7', 'rolling_mean_tmp_1_14', 'price_momentum', 'rolling_mean_tmp_1_60', 'rolling_mean_tmp_14_60', 'sales_lag_42', 'tm_y', 'sales_lag_29', 'rolling_mean_tmp_14_7', 'enc_cat_id_std', 'sales_lag_36', 'price_mean', 'sales_lag_37', 'sales_lag_28', 'rolling_std_180', 'enc_item_id_std', 'rolling_mean_14', 'tm_m', 'rolling_mean_tmp_14_14', 'rolling_mean_tmp_1_30', 'price_min', 'sales_lag_33', 'tm_w_end', 'rolling_mean_7', 'item_nunique', 'price_momentum_m', 'tm_w', 'enc_dept_id_mean', 'price_nunique', 'rolling_mean_30', 'rolling_mean_180', 'rolling_mean_tmp_1_7', 'sales_lag_40', 'tm_dw', 'rolling_std_60', 'rolling_std_7', 'rolling_mean_tmp_7_60', 'rolling_std_30', 'eme_0', 'eme_1', 'eme_2', 'eme_3', 'eme_4', 'eme_5', 'eme_6', 'eme_7', 'eme_8', 'eme_9', 'eme_10', 'eme_11', 'eme_12', 'eme_13', 'eme_14', 'eme_15', 'eme_16', 'eme_17', 'eme_18', 'eme_19', 'eme_20', 'eme_21', 'eme_22', 'eme_23', 'eme_24', 'eme_25', 'eme_26', 'eme_27', 'eme_28', 'cat_id_FOODS', 'cat_id_HOBBIES', 'cat_id_HOUSEHOLD', 'event_type_2_Cultural', 'event_type_2_Religious', 'snap_CA_pca', 'snap_TX_pca', 'snap_WI_pca']\n","finish：WI_3\n","[0]\teval-rmse:3.89084\n","Will train until eval-rmse hasn't improved in 100 rounds.\n","[100]\teval-rmse:1.88542\n","[200]\teval-rmse:1.87355\n","[300]\teval-rmse:1.86864\n","[400]\teval-rmse:1.86407\n","[500]\teval-rmse:1.86054\n","[600]\teval-rmse:1.85703\n","[700]\teval-rmse:1.85681\n","[800]\teval-rmse:1.85637\n","Stopping. Best iteration:\n","[735]\teval-rmse:1.85603\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"J3ty0UFVCDKh","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1594958211971,"user_tz":-480,"elapsed":945,"user":{"displayName":"余凯","photoUrl":"","userId":"13334016005065607071"}}},"source":["MODEL_FEATURES = ['rolling_mean_60', 'rolling_std_14', 'sales_lag_35', 'enc_dept_id_std', 'rolling_mean_tmp_7_30', 'enc_cat_id_mean', 'sales_lag_30', 'sales_lag_34', 'sales_lag_39', 'enc_item_id_mean', 'tm_wm', 'price_norm', 'rolling_mean_tmp_14_30', 'sales_lag_41', 'rolling_mean_tmp_7_14', 'sales_lag_38', 'price_std', 'sell_price', 'tm_d', 'sales_lag_31', 'price_momentum_y', 'price_max', 'sales_lag_32', 'rolling_mean_tmp_7_7', 'rolling_mean_tmp_1_14', 'price_momentum', 'rolling_mean_tmp_1_60', 'rolling_mean_tmp_14_60', 'sales_lag_42', 'tm_y', 'sales_lag_29', 'rolling_mean_tmp_14_7', 'enc_cat_id_std', 'sales_lag_36', 'price_mean', 'sales_lag_37', 'sales_lag_28', 'rolling_std_180', 'enc_item_id_std', 'rolling_mean_14', 'tm_m', 'rolling_mean_tmp_14_14', 'rolling_mean_tmp_1_30', 'price_min', 'sales_lag_33', 'tm_w_end', 'rolling_mean_7', 'item_nunique', 'price_momentum_m', 'tm_w', 'enc_dept_id_mean', 'price_nunique', 'rolling_mean_30', 'rolling_mean_180', 'rolling_mean_tmp_1_7', 'sales_lag_40', 'tm_dw', 'rolling_std_60', 'rolling_std_7', 'rolling_mean_tmp_7_60', 'rolling_std_30', 'eme_0', 'eme_1', 'eme_2', 'eme_3', 'eme_4', 'eme_5', 'eme_6', 'eme_7', 'eme_8', 'eme_9', 'eme_10', 'eme_11', 'eme_12', 'eme_13', 'eme_14', 'eme_15', 'eme_16', 'eme_17', 'eme_18', 'eme_19', 'eme_20', 'eme_21', 'eme_22', 'eme_23', 'eme_24', 'eme_25', 'eme_26', 'eme_27', 'eme_28', 'cat_id_FOODS', 'cat_id_HOBBIES', 'cat_id_HOUSEHOLD', 'event_type_2_Cultural', 'event_type_2_Religious', 'snap_CA_pca', 'snap_TX_pca', 'snap_WI_pca']"],"execution_count":9,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"K-6G3-elfFma","colab_type":"text"},"source":["## 预测"]},{"cell_type":"code","metadata":{"id":"bV36FmMfPuOR","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1594959276639,"user_tz":-480,"elapsed":1064209,"user":{"displayName":"余凯","photoUrl":"","userId":"13334016005065607071"}},"outputId":"56dd906e-1c77-4126-d7da-810c72328f2f"},"source":["USE_AUX = True\n","all_preds = pd.DataFrame()\n","base_test = get_base_test() \n","# 3902720 rows × 66 columns 62 + 4（event_name_1_win、store_id、event_name_2_win、event_name_1_win_1）\n","# 记住：后面这个特征是新加的，原来只有62 + 12(lag+rolling) = 72\n","main_time = time.time()\n","\n","for PREDICT_DAY in range(1,29):    \n","  print('Predict | Day:', PREDICT_DAY)\n","  start_time = time.time() \n","  grid_df = base_test.copy() \n","  grid_df = pd.concat([grid_df, df_parallelize_run(make_lag_roll, ROLS_SPLIT)], axis=1) \n","  # print(grid_df.columns)\n","  print('finish roll')\n","  # 3902720(30490×128) × 78(66 + 12(lag+rolling)) \n","  # rolling_mean_tmp_14_60 每组128个数据，相当于每个id的128天这个时序，lag = 14，到1942到1942+14天有数据\n","  # 具体看一下 datasets 文件夹里面的 HOUSEHOLD_2_490_WI_3.csv文件 \n","  for store_id in STORES_IDS:\n","    model_bin = 'xgb_model_{}_v{}_A.bin'.format(store_id, str(VER))\n","    if USE_AUX:\n","      model_path = model_pkl_path + model_bin\n","    estimator = pickle.load(open(model_path, 'rb')) # 读取训练好的模型\n","\n","\n","    day_mask = base_test['d'] == (END_TRAIN + PREDICT_DAY) # 1942、1943、...、1969\n","    store_mask = base_test['store_id'] == store_id\n","    mask = (day_mask) & (store_mask)\n","\n","    test = xgb.DMatrix(grid_df[mask][MODEL_FEATURES]) \n","    base_test[TARGET][mask] = estimator.predict(test) # 测试集也要封装成DMatrix形式\n","\n","  temp_df = base_test[day_mask][['id',TARGET]]\n","  # print(temp_df)\n","  temp_df.columns = ['id', 'F' + str(PREDICT_DAY)]\n","  if 'id' in list(all_preds):\n","    all_preds = all_preds.merge(temp_df, on=['id'], how='left')\n","  else:\n","    all_preds = temp_df.copy()\n","      \n","  print('#'*10, ' %0.2f min round |' % ((time.time() - start_time) / 60),\n","          ' %0.2f min total |' % ((time.time() - main_time) / 60),\n","          ' %0.2f day sales |' % (temp_df['F' + str(PREDICT_DAY)].sum()))\n","  del temp_df\n","    \n","all_preds = all_preds.reset_index(drop=True)\n","all_preds.to_csv(pred_path + 'per_store_pred(xgb)_A.csv',index=False)\n","\n","\n","# 用于生成提交预测的文件\n","# submission = pd.read_csv(datasets_path + 'sample_submission.csv')[['id']] \n","# submission = submission.merge(all_preds, on=['id'], how='left').fillna(0)\n","# submission.to_csv(sub_path + 'submission_by_stores(xgb)_A.csv', index=False) "],"execution_count":10,"outputs":[{"output_type":"stream","text":["Predict | Day: 1\n","finish roll\n","##########  0.63 min round |  0.63 min total |  36363.09 day sales |\n","Predict | Day: 2\n","finish roll\n","##########  0.64 min round |  1.27 min total |  33799.41 day sales |\n","Predict | Day: 3\n","finish roll\n","##########  0.61 min round |  1.87 min total |  33459.25 day sales |\n","Predict | Day: 4\n","finish roll\n","##########  0.61 min round |  2.49 min total |  33833.19 day sales |\n","Predict | Day: 5\n","finish roll\n","##########  0.61 min round |  3.10 min total |  39352.62 day sales |\n","Predict | Day: 6\n","finish roll\n","##########  0.62 min round |  3.72 min total |  47197.91 day sales |\n","Predict | Day: 7\n","finish roll\n","##########  0.61 min round |  4.33 min total |  50513.09 day sales |\n","Predict | Day: 8\n","finish roll\n","##########  0.62 min round |  4.95 min total |  42379.87 day sales |\n","Predict | Day: 9\n","finish roll\n","##########  0.62 min round |  5.57 min total |  41488.19 day sales |\n","Predict | Day: 10\n","finish roll\n","##########  0.61 min round |  6.18 min total |  36904.49 day sales |\n","Predict | Day: 11\n","finish roll\n","##########  0.61 min round |  6.79 min total |  38537.13 day sales |\n","Predict | Day: 12\n","finish roll\n","##########  0.61 min round |  7.40 min total |  43752.96 day sales |\n","Predict | Day: 13\n","finish roll\n","##########  0.61 min round |  8.00 min total |  51153.01 day sales |\n","Predict | Day: 14\n","finish roll\n","##########  0.61 min round |  8.61 min total |  44794.95 day sales |\n","Predict | Day: 15\n","finish roll\n","##########  0.61 min round |  9.22 min total |  42152.13 day sales |\n","Predict | Day: 16\n","finish roll\n","##########  0.60 min round |  9.82 min total |  36968.43 day sales |\n","Predict | Day: 17\n","finish roll\n","##########  0.61 min round |  10.43 min total |  38322.62 day sales |\n","Predict | Day: 18\n","finish roll\n","##########  0.63 min round |  11.06 min total |  38678.76 day sales |\n","Predict | Day: 19\n","finish roll\n","##########  0.63 min round |  11.68 min total |  41870.13 day sales |\n","Predict | Day: 20\n","finish roll\n","##########  0.63 min round |  12.31 min total |  51304.72 day sales |\n","Predict | Day: 21\n","finish roll\n","##########  0.65 min round |  12.96 min total |  52963.62 day sales |\n","Predict | Day: 22\n","finish roll\n","##########  0.64 min round |  13.60 min total |  39280.15 day sales |\n","Predict | Day: 23\n","finish roll\n","##########  0.65 min round |  14.24 min total |  35918.42 day sales |\n","Predict | Day: 24\n","finish roll\n","##########  0.64 min round |  14.89 min total |  35311.67 day sales |\n","Predict | Day: 25\n","finish roll\n","##########  0.65 min round |  15.54 min total |  34970.91 day sales |\n","Predict | Day: 26\n","finish roll\n","##########  0.65 min round |  16.18 min total |  39570.17 day sales |\n","Predict | Day: 27\n","finish roll\n","##########  0.64 min round |  16.83 min total |  48289.18 day sales |\n","Predict | Day: 28\n","finish roll\n","##########  0.64 min round |  17.47 min total |  48961.86 day sales |\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"a9StIQuqjMaT","colab_type":"code","colab":{}},"source":["################################## 本地wrmse #############################################################\n","import numpy as np\n","import pandas as pd\n","from sklearn.metrics import mean_squared_error\n","from scipy.sparse import csr_matrix\n","import gc\n","\n","# 加载前面预先计算好的各个权重\n","sw_df = pd.read_pickle(Metric_pkl_path + 'sw_df.pkl')\n","S = sw_df.s.values\n","W = sw_df.w.values\n","SW = sw_df.sw.values\n","roll_mat_df = pd.read_pickle(Metric_pkl_path + 'roll_mat_df.pkl')\n","roll_index = roll_mat_df.index\n","roll_mat_csr = csr_matrix(roll_mat_df.values)\n","\n","\n","def rollup(v):\n","    return (v.T*roll_mat_csr.T).T\n","\n","# 计算 WRMSSE 评估指标\n","def wrmsse(preds, y_true, score_only=False, s = S, w = W, sw=SW):\n","    '''\n","    preds - Predictions: pd.DataFrame of size (30490 rows, N day columns)\n","    y_true - True values: pd.DataFrame of size (30490 rows, N day columns)\n","    sequence_length - np.array of size (42840,)\n","    sales_weight - sales weights based on last 28 days: np.array (42840,)\n","    '''\n","    \n","    if score_only:\n","        return np.sum(\n","                np.sqrt(\n","                    np.mean(\n","                        np.square(rollup(preds.values-y_true.values))\n","                            ,axis=1)) * sw )*(1/12)\n","    else: \n","        score_matrix = (np.square(rollup(preds.values-y_true.values)) * np.square(w)[:, None])  / s[:, None]\n","        score = np.sum(np.sqrt(np.mean(score_matrix,axis=1)))*(1/12)\n","        return score, score_matrix"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Mh_LK8yskYe_","colab_type":"code","colab":{}},"source":["## 预测值\n","cols = [f'F{i}' for i in range(1,29)]\n","pred = all_preds1[cols]\n","## 真值1\n","cols_1 = [f'd_{i}' for i in range(1886, 1914)]\n","true_1 = pd.read_csv(datasets_path + 'sales_train_validation.csv')[col2]\n","## 真值2\n","cols_2 = [f'd_{i}' for i in range(1914, 1942)]\n","true_2 = pd.read_csv(datasets_path + 'sales_train_evaluation.csv')[cols_2]\n","## 进行测试\n","wrmsse(true_2, pred ,score_only=True)  "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"tc4W3-XD6sNM","colab_type":"text"},"source":["## 某个商店进行贝叶斯调参"]},{"cell_type":"code","metadata":{"id":"VXHlTryV7POW","colab_type":"code","colab":{}},"source":["STORES_IDS = ['CA_1']\n","grid_df, features_columns = get_data_by_store('CA_1')\n","day = 1941\n","\n","grid_df1 = grid_df[grid_df['d'] <= day]\n","del grid_df\n","!pip install bayesian-optimization\n","\n","from bayes_opt import BayesianOptimization\n","\n","def rmse(y, y_pred):\n","  return np.sqrt(np.mean(np.square(y - y_pred)))\n","df = grid_df1\n","fe = features_columns\n","# 1000到1941-28-28 作为训练集\n","tr_x, tr_y = df[(df['d'] >= 1000) & (df['d'] <= (day-28-28))][fe], df[(df['d'] >= 1000) & (df['d'] <= (day-28-28))]['sales'] \n","# 1941-28-28到1941-28 作为测试集\n","vl_x, vl_y = df[(df['d'] > (day-28-28)) & (df['d'] <= (day-28))][fe], df[(df['d'] > (day-28-28)) & (df['d'] <= (day-28))]['sales']\n","\n","train_data = lgb.Dataset(tr_x, label=tr_y)\n","valid_data = lgb.Dataset(vl_x, label=vl_y)\n","\n","# 1914到1941 作为测试集，用训练的模型预测它的\"sales\"，再与真实的\"sales\"计算RMSE\n","test_df = df[df['d']>(day-28)].reset_index(drop=True)\n","\n","# 定义黑盒函数\n","def lgb_cv(tweedie_variance_power, subsample, subsample_freq, learning_rate, num_leaves, min_data_in_leaf,\n","      feature_fraction, max_bin, n_estimators, lambda_l2, sub_row, sub_feature, bagging_freq):\n","\n","\n","    lgb_params = {\n","                    'boosting_type': 'gbdt',\n","                    'objective': 'tweedie',\n","                    'tweedie_variance_power': tweedie_variance_power,\n","                    'metric': 'rmse',\n","                    'subsample': subsample,\n","                    'subsample_freq': int(subsample_freq),\n","                    'learning_rate': learning_rate,\n","                    'num_leaves': int(num_leaves),\n","                    'min_data_in_leaf': int(min_data_in_leaf),\n","                    'feature_fraction': feature_fraction,\n","                    'max_bin': int(max_bin),\n","                    'n_estimators': int(n_estimators),\n","                    'boost_from_average': False,\n","                    'seed': 42,  \n","                    'lambda_l2':lambda_l2,\n","                    'sub_row':sub_row,  \n","                    'sub_feature':sub_feature,\n","                    'bagging_freq':int(bagging_freq),               \n","                }\n","\n","    stimator = lgb.train(lgb_params, train_data) \n","    # valid_sets = [train_data, valid_data] 这个是用来显示training's rmse和valid_1's rmse，而 verbose_eval : 迭代多少次打印\n","\n","    test_df['preds'] = stimator.predict(test_df[fe])\n","    base_score = rmse(test_df['sales'], test_df['preds'])\n","\n","    return -base_score\n","\n","# 给定超参数搜索空间\n","opt = BayesianOptimization(\n","                lgb_cv,\n","                {\n","                    'tweedie_variance_power': (1, 1.5),\n","                    'subsample': (0.5, 1.0),\n","                    'subsample_freq': (0, 5),\n","                    'learning_rate': (0, 1),\n","                    'num_leaves':(2**10-1,2**15-1),\n","                    'min_data_in_leaf':(2**10-1,2**15-1),\n","                    'feature_fraction':(0.4,1),\n","                    'max_bin':(80,150),\n","                    'n_estimators':(1000,1700),\n","                    'lambda_l2':(0,0.2),\n","                    'sub_row':(0.6,1),\n","                    'sub_feature':(0.6,1.0),\n","                    'bagging_freq':(0,5),\n","                }\n","              )\n","opt.maximize(n_iter = 20) # 最大化黑盒函数，迭代100次\n","\n","rf_bo.max # 返回黑盒函数值最大的超参数"],"execution_count":null,"outputs":[]}]}